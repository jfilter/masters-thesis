{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T12:55:52.635894Z",
     "start_time": "2018-12-13T12:55:52.628132Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import fastai\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import sacred\n",
    "import sklearn.metrics\n",
    "from fastai.basic_train import get_preds\n",
    "from fastai.callbacks import *\n",
    "from fastai.datasets import *\n",
    "from fastai.imports import nn, torch\n",
    "from fastai.metrics import *\n",
    "from fastai.text import *\n",
    "from fastai.text.data import DataBunch\n",
    "from fastai.train import *\n",
    "from fastai.vision import *\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver\n",
    "from sklearn import metrics\n",
    "\n",
    "import news_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--exp\")\n",
    "parser.add_argument(\"--device\", type=int)\n",
    "parser.add_argument(\"--start\", type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "EX_PA = Path('/mnt/data/group07/johannes/ynacc_proc/replicate/' + args.exp)\n",
    "\n",
    "torch.cuda.set_device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T12:55:53.779798Z",
     "start_time": "2018-12-13T12:55:53.771413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.33\n"
     ]
    }
   ],
   "source": [
    "print(fastai.__version__)\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient['10000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T13:07:05.885592Z",
     "start_time": "2018-12-13T13:07:05.876913Z"
    }
   },
   "outputs": [],
   "source": [
    "myresults = mydb[\"metrics\"].aggregate([{\n",
    "    \"$match\": {\"name\": \"valid_loss\"}  # only consider val loss\n",
    "},\n",
    "    {\"$unwind\": \"$values\"},\n",
    "    {\"$group\":\n",
    "     {'_id': '$_id',\n",
    "      'minval': {'$min': \"$values\"}, 'run_id' : { '$first': '$run_id' }}\n",
    "     },  # find min values\n",
    "    {\"$sort\": {\"minval\": 1}}  # sort\n",
    "])\n",
    "\n",
    "# get best run id in the metrics table\n",
    "best_run_id = sorted(list(myresults), key=lambda x: x['minval'])[0]['run_id']\n",
    "\n",
    "# get the exp id for the language model\n",
    "best_lm_exp_id = list(mydb['runs'].find({'_id': best_run_id}))[0]['config']['exp_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.load(EX_PA)\n",
    "learn_lm = language_model_learner(data_lm).load(\n",
    "    EX_PA/\"models\"/best_lm_exp_id, device=\"cpu\")\n",
    "learn_lm.save_encoder('encoder_' + best_lm_exp_id)\n",
    "learn_lm_vocab = data_lm.train_ds.vocab\n",
    "del data_lm\n",
    "del learn_lm\n",
    "\n",
    "\n",
    "def setup_data(clas):\n",
    "    split_path = Path('~/data/ynacc_proc/replicate/split')\n",
    "    \n",
    "    if args.exp.endswith('_ner'):\n",
    "        data_clas_train = pd.read_csv(split_path/'train_ner.csv')\n",
    "        data_clas_val = pd.read_csv(split_path/'val_ner.csv')\n",
    "    else:\n",
    "        data_clas_train = pd.read_csv(split_path/'train.csv')\n",
    "        data_clas_val = pd.read_csv(split_path/'val.csv')        \n",
    "\n",
    "    data_clas_train = data_clas_train[[clas, 'text_proc']]\n",
    "    data_clas_val = data_clas_val[[clas, 'text_proc']]\n",
    "\n",
    "    data_clas_train = data_clas_train.dropna()\n",
    "    data_clas_val = data_clas_val.dropna()\n",
    "\n",
    "    data_clas_train[clas] = data_clas_train[clas].astype(int)\n",
    "    data_clas_val[clas] = data_clas_val[clas].astype(int)\n",
    "\n",
    "    data_clas = TextClasDataBunch.from_df(EX_PA, data_clas_train, data_clas_val,\n",
    "                                          vocab=learn_lm_vocab, bs=64, text_cols=['text_proc'], label_cols=[clas],)\n",
    "    return data_clas\n",
    "\n",
    "\n",
    "def run_for_class(clas, it=5):\n",
    "    print('work on ' + clas)\n",
    "    torch.cuda.empty_cache()\n",
    "    data_clas = setup_data(clas)\n",
    "    encoder_name = 'encoder_' + model_id\n",
    "    drop_mult = 1\n",
    "\n",
    "    learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "    learn.load_encoder(encoder_name)\n",
    "\n",
    "    optim_lr = news_utils.fastai.get_optimal_lr(learn, runs=7)\n",
    "\n",
    "    ex = Experiment(db_name + '_' + clas)\n",
    "    ex.observers.append(MongoObserver.create(db_name=db_name))\n",
    "\n",
    "    @ex.config\n",
    "    def my_config():\n",
    "        exp_id = datetime.datetime.now().strftime(\"%Y_%_m_%d_%H_%M_%S_%f\")\n",
    "        factor = 3\n",
    "        wd = 1e-7\n",
    "        moms = (0.8, 0.7)\n",
    "        full_epochs = 10\n",
    "\n",
    "    @ex.main\n",
    "    def run_exp(exp_id, drop_mult, lr, moms, wd, factor, full_epochs):\n",
    "\n",
    "        lrs = [lr / (factor ** (4 - x)) for x in range(4)] + [lr]\n",
    "\n",
    "        learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "        learn.load_encoder(encoder_name)\n",
    "\n",
    "        learn.metrics += [news_utils.fastai.F1Macro(),\n",
    "                          news_utils.fastai.F1Weighted()]\n",
    "        learn.callbacks += [\n",
    "            SaveModelCallback(learn, name=exp_id),\n",
    "            news_utils.fastai.SacredLogger(learn, ex),\n",
    "        ]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            epochs = 1\n",
    "            if i in [1, 2]:\n",
    "                learn.freeze_to(-i)\n",
    "            else:\n",
    "                learn.unfreeze()\n",
    "                epochs = full_epochs\n",
    "            learn.fit_one_cycle(epochs, np.array(lrs), wd=wd, moms=moms)\n",
    "\n",
    "    for _ in range(it):\n",
    "        ex.run(config_updates={\"lr\": optim_lr, \"drop_mult\": drop_mult})\n",
    "\n",
    "\n",
    "i = -1\n",
    "for x in ['claudience', 'clpersuasive', 'clsentiment', 'clagreement', 'cldisagreement', 'clinformative', 'clmean', 'clcontroversial', 'cltopic']:\n",
    "    torch.cuda.empty_cache()\n",
    "    i += 1\n",
    "    if not args.start is None and args.start > i:\n",
    "        continue\n",
    "    run_for_class(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
