{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T13:25:10.859032Z",
     "start_time": "2018-11-28T13:25:10.829309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.text import *\n",
    "from fastai.text.data import DataBunch\n",
    "from fastai.datasets import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from fastai.metrics import *\n",
    "from fastai.train import *\n",
    "from fastai.vision import *\n",
    "from fastai.imports import nn, torch\n",
    "from sklearn import metrics\n",
    "from fastai.callbacks import *\n",
    "from fastai.basic_train import get_preds\n",
    "\n",
    "import sacred\n",
    "\n",
    "import sklearn.metrics\n",
    "import datetime\n",
    "import news_utils\n",
    "from pathlib import Path\n",
    "\n",
    "import fastai\n",
    "fastai.__version__\n",
    "\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T11:35:14.572082Z",
     "start_time": "2018-11-28T11:35:14.542663Z"
    }
   },
   "outputs": [],
   "source": [
    "EX_PA = Path('/mnt/data/group07/johannes/ynacc_proc/replicate/20k')\n",
    "model_id = '2018_11_25_23_51_55_431399'# best without overfitting\n",
    "db_name = '20k_class_no_over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T11:35:24.436639Z",
     "start_time": "2018-11-28T11:35:23.101144Z"
    }
   },
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.load(EX_PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T10:24:40.489768Z",
     "start_time": "2018-11-28T10:24:36.520349Z"
    }
   },
   "outputs": [],
   "source": [
    "learn_lm = language_model_learner(data_lm).load(EX_PA/\"models\"/model_id, device=\"cpu\")\n",
    "learn_lm.save_encoder('encoder_' + model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T11:35:26.429244Z",
     "start_time": "2018-11-28T11:35:24.472831Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_data(clas):\n",
    "    split_path = Path('~/data/ynacc_proc/replicate/split')\n",
    "\n",
    "    data_clas_train = pd.read_csv(split_path/'train_proc_with_ner.csv')\n",
    "    data_clas_val = pd.read_csv(split_path/'val_proc_with_ner.csv')\n",
    "\n",
    "    data_clas_train = data_clas_train[[clas, 'text_proc']]\n",
    "    data_clas_val = data_clas_val[[clas, 'text_proc']]\n",
    "\n",
    "    data_clas_train = data_clas_train.dropna()\n",
    "    data_clas_val = data_clas_val.dropna()\n",
    "\n",
    "    data_clas_train[clas] = data_clas_train[clas].astype(int)\n",
    "    data_clas_val[clas] = data_clas_val[clas].astype(int)\n",
    "\n",
    "    data_clas = TextClasDataBunch.from_df(EX_PA, data_clas_train, data_clas_val,\n",
    "                                          vocab=data_lm.train_ds.vocab, bs=64, text_cols=['text_proc'], label_cols=[clas],)\n",
    "    return data_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T12:24:07.421665Z",
     "start_time": "2018-11-28T12:19:03.235377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 04:37\n",
      "epoch  train_loss  valid_loss  accuracy  F1_macro  F1_weighted\n",
      "1      0.439330    0.400339    0.845626  0.516530  0.907203     (00:29)\n",
      "2      0.406791    0.405685    0.845626  0.516530  0.907203     (00:27)\n",
      "3      0.445035    0.409734    0.849057  0.535492  0.906663     (00:29)\n",
      "4      0.429370    0.402804    0.845626  0.524935  0.904542     (00:29)\n",
      "5      0.427848    0.403102    0.845626  0.524935  0.904542     (00:27)\n",
      "6      0.408138    0.395928    0.842196  0.522642  0.899809     (00:23)\n",
      "7      0.391929    0.402716    0.843911  0.515449  0.904813     (00:29)\n",
      "8      0.413590    0.415070    0.847341  0.542091  0.901850     (00:26)\n",
      "9      0.424379    0.406475    0.849057  0.543396  0.904165     (00:29)\n",
      "10     0.394992    0.403925    0.849057  0.543396  0.904165     (00:25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_for_class(clas, it=5):\n",
    "    data_clas = setup_data(clas)\n",
    "    \n",
    "    drop_mult = 1\n",
    "    text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "    optim_lr = news_utils.fastai.get_optimal_lr(learn)\n",
    "\n",
    "    ex = Experiment(db_name + '_' + clas)\n",
    "    ex.observers.append(MongoObserver.create(db_name=db_name))\n",
    "\n",
    "    @ex.config\n",
    "    def my_config():\n",
    "        exp_id = datetime.datetime.now().strftime(\"%Y_%_m_%d_%H_%M_%S_%f\")\n",
    "        factor = 3\n",
    "        wd = 1e-7\n",
    "        moms = (0.8, 0.7)\n",
    "        drop_mult = drop_mult\n",
    "        full_epochs = 10\n",
    "        lr = optim_lr\n",
    "\n",
    "    @ex.main\n",
    "    def run_exp(exp_id, drop_mult, lr, moms, wd, factor):\n",
    "        encoder_name = 'encoder_' + model_id\n",
    "\n",
    "        lrs = [lr / (factor ** (4 - x)) for x in range(4)] + [lr]\n",
    "        \n",
    "        learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "        learn.load_encoder(encoder_name)\n",
    "\n",
    "        learn.metrics += [news_utils.fastai.F1Macro(), news_utils.fastai.F1Weighted()]\n",
    "        learn.callbacks += [\n",
    "            SaveModelCallback(learn, name=exp_id),\n",
    "        ]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            epochs = 1\n",
    "            if i in [1, 2]:\n",
    "                learn.freeze_to(-i)\n",
    "            else:\n",
    "                learn.unfreeze()\n",
    "        #         learn.callbacks += [EarlyStoppingCallback(learn, patience=5)]\n",
    "                epochs = full_epochs\n",
    "        #             learn.fit_one_cycle(epochs, np.array(lrs) * 1 / (i ** 4), wd=wd, moms=moms)\n",
    "            learn.fit_one_cycle(epochs, np.array(lrs), wd=wd, moms=moms)\n",
    "    \n",
    "    for _ in range(it):\n",
    "        exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_class('clcontroversial')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
