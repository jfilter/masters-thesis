{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/home/group7/masters-thesis/ompc",
    "dependencies": [
      "bpemb==0.2.9",
      "fastai==1.0.42",
      "fastprogress==0.1.18",
      "matplotlib==3.0.2",
      "numpy==1.15.4",
      "pandas==0.23.4",
      "requests==2.21.0",
      "sacred==0.7.4",
      "scipy==1.2.0",
      "spacy-nightly==2.1.0a6",
      "torch==1.0.0"
    ],
    "mainfile": "2shftlm.py",
    "name": "shortppompclm2",
    "repositories": [],
    "sources": [
      [
        "2shftlm.py",
        "_sources/2shftlm_d1b650add96204b47ca8486a2883a17b.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/home/group7/anaconda3/envs/dev/lib/python3.7/site-packages/sacred/config/captured_function.py\", line 46, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"2shftlm.py\", line 56, in my_main\n    learn = language_model_learner(data_lm_ft, drop_mult=drop_mult)\n",
    "  File \"/home/group7/dev/fastai/fastai/text/learner.py\", line 134, in language_model_learner\n    learn = LanguageLearner(data, model, bptt, split_func=lm_split, **kwargs)\n",
    "  File \"/home/group7/dev/fastai/fastai/text/learner.py\", line 52, in __init__\n    super().__init__(data, model, **kwargs)\n",
    "  File \"<string>\", line 16, in __init__\n",
    "  File \"/home/group7/dev/fastai/fastai/basic_train.py\", line 153, in __post_init__\n    self.model = self.model.to(self.data.device)\n",
    "  File \"/home/group7/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 381, in to\n    return self._apply(convert)\n",
    "  File \"/home/group7/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 187, in _apply\n    module._apply(fn)\n",
    "  File \"/home/group7/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 187, in _apply\n    module._apply(fn)\n",
    "  File \"/home/group7/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 193, in _apply\n    param.data = fn(param.data)\n",
    "  File \"/home/group7/anaconda3/envs/dev/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 379, in convert\n    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)\n",
    "RuntimeError: CUDA error: out of memory\n"
  ],
  "heartbeat": "2019-04-07T10:21:46.884710",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Core(TM) i9-7900X CPU @ 3.30GHz",
    "gpus": {
      "driver_version": "396.26",
      "gpus": [
        {
          "model": "GeForce GTX 1080 Ti",
          "persistence_mode": false,
          "total_memory": 11178
        },
        {
          "model": "GeForce GTX 1080 Ti",
          "persistence_mode": false,
          "total_memory": 11178
        },
        {
          "model": "GeForce GTX 1080 Ti",
          "persistence_mode": false,
          "total_memory": 11178
        },
        {
          "model": "GeForce GTX 1080 Ti",
          "persistence_mode": false,
          "total_memory": 11176
        }
      ]
    },
    "hostname": "idun",
    "os": [
      "Linux",
      "Linux-4.15.0-46-generic-x86_64-with-debian-stretch-sid"
    ],
    "python_version": "3.7.1"
  },
  "meta": {
    "command": "my_main",
    "options": {
      "--beat_interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print_config": false,
      "--priority": null,
      "--queue": false,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2019-04-07T10:21:07.722320",
  "status": "FAILED",
  "stop_time": "2019-04-07T10:21:46.887870"
}