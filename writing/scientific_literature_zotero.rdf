<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns:z="http://www.zotero.org/namespaces/export#"
 xmlns:dcterms="http://purl.org/dc/terms/"
 xmlns:bib="http://purl.org/net/biblio#"
 xmlns:foaf="http://xmlns.com/foaf/0.1/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:link="http://purl.org/rss/1.0/modules/link/"
 xmlns:prism="http://prismstandard.org/namespaces/1.2/basic/"
 xmlns:vcard="http://nwalsh.com/rdf/vCard#">
    <bib:Document rdf:about="http://zotero.org/support/quick_start_guide">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Center for History and New Media</foaf:surname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_2"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://zotero.org/support/quick_start_guide</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:title>Zotero Quick Start Guide</dc:title>
    </bib:Document>
    <bib:Memo rdf:about="#item_2">
        <rdf:value>&lt;p&gt;&lt;strong&gt;Welcome to Zotero!&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.&lt;/p&gt;&lt;p&gt;Thanks for installing Zotero.&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="#item_12">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>R F</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Napoles</foaf:surname>
                        <foaf:givenname>Courtney</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pappu</foaf:surname>
                        <foaf:givenname>Aasish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tetreault</foaf:surname>
                        <foaf:givenname>Joel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_11"/>
        <bib:pages>4</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online news platforms curate high-quality content for their readers and, in many cases, users can post comments in response. While comment threads routinely contain unproductive banter, insults, or users “shouting” over each other, there are often good discussions buried among the noise. In this paper, we deﬁne a new task of identifying “good” conversations, which we call ERICs—Engaging, Respectful, and/or Informative Conversations. Our model successfully identiﬁes ERICs posted in response to online news articles with F1 = 0.73 and F1 = 0.91 in debate forums.</dcterms:abstract>
        <dc:title>Automatically Identifying Good Conversations Online (Yes, They Do Exist!)</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_11">
        <z:itemType>attachment</z:itemType>
        <dc:title>Napoles et al. - Automatically Identifying Good Conversations Onlin.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/W17-4218">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:identifier>DOI 10.18653/v1/W17-4218</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kolhatkar</foaf:surname>
                        <foaf:givenname>Varada</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taboada</foaf:surname>
                        <foaf:givenname>Maite</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_18"/>
        <link:link rdf:resource="#item_10"/>
        <dc:subject>deep</dc:subject>
        <dc:subject>nytpicks</dc:subject>
        <dc:subject>ynacc</dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/W17-4218</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>100-105</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-07-25 15:15:44</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We examine the extent to which we are able to automatically identify constructive online comments. We build several classiﬁers using New York Times Picks as positive examples and non-constructive thread comments from the Yahoo News Annotated Comments Corpus as negative examples of constructive online comments. We evaluate these classiﬁers on a crowdannotated corpus containing 1,121 comments. Our best classiﬁer achieves a top F1 score of 0.84.</dcterms:abstract>
        <dc:title>Using New York Times Picks to Identify Constructive Comments</dc:title>
    </rdf:Description>
    <bib:Memo rdf:about="#item_18">
        <rdf:value>&lt;p&gt;- on individual comments&lt;/p&gt;
&lt;p&gt;- NYT picks&lt;/p&gt;
&lt;p&gt;- Pos: NYT picks&lt;/p&gt;
&lt;p&gt;- Neg: all comments in a toxic threads of &lt;span class=&quot;col-11 text-gray-dark mr-2&quot;&gt;YNACC&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Focused on SVM Machine Learning&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_10">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kolhatkar and Taboada - 2017 - Using New York Times Picks to Identify Constructiv.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_14">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <prism:volume>5</prism:volume><prism:number>1</prism:number>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Diakopoulos</foaf:surname>
                        <foaf:givenname>Nicholas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_19"/>
        <link:link rdf:resource="#item_9"/>
        <dc:subject>low</dc:subject>
        <bib:pages>20</bib:pages>
        <dc:date>2015</dc:date>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Picking the NYT Picks: Editorial Criteria and Automation in the Curation of Online News Comments</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_19">
        <rdf:value>&lt;p&gt;More focused on the backgroud of good comments&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_9">
        <z:itemType>attachment</z:itemType>
        <dc:title>Diakopoulos - 2015 - Picking the NYT Picks Editorial Criteria and Auto.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/W17-0802">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:identifier>DOI 10.18653/v1/W17-0802</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Napoles</foaf:surname>
                        <foaf:givenname>Courtney</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tetreault</foaf:surname>
                        <foaf:givenname>Joel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pappu</foaf:surname>
                        <foaf:givenname>Aasish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rosato</foaf:surname>
                        <foaf:givenname>Enrica</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Provenzale</foaf:surname>
                        <foaf:givenname>Brian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_8"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/W17-0802</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>13-23</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-07-25 15:15:46</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>This work presents a dataset and annotation scheme for the new task of identifying “good” conversations that occur online, which we call ERICs: Engaging, Respectful, and/or Informative Conversations. We develop a taxonomy to reﬂect features of entire threads and individual comments which we believe contribute to identifying ERICs; code a novel dataset of Yahoo News comment threads (2.4k threads and 10k comments) and 1k threads from the Internet Argument Corpus; and analyze the features characteristic of ERICs. This is one of the largest annotated corpora of online human dialogues, with the most detailed set of annotations. It will be valuable for identifying ERICs and other aspects of argumentation, dialogue, and discourse.</dcterms:abstract>
        <dc:title>Finding Good Conversations Online: The Yahoo News Annotated Comments Corpus</dc:title>
        <z:shortTitle>Finding Good Conversations Online</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_8">
        <z:itemType>attachment</z:itemType>
        <dc:title>Napoles et al. - 2017 - Finding Good Conversations Online The Yahoo News .pdf</dc:title>
        <link:type>application/pdf</link:type>
        <dc:description>&lt;div class=&quot;page&quot; title=&quot;Page 9&quot;&gt;
&lt;div class=&quot;section&quot;&gt;
&lt;div class=&quot;layoutArea&quot;&gt;
&lt;div class=&quot;column&quot;&gt;
&lt;p&gt;&lt;span style=&quot;font-size: 11.000000pt; font-family: 'NimbusRomNo9L';&quot;&gt;These results support the findings of previous work and indicate that thumbs up or thumbs down alone &lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</dc:description>
    </z:Attachment>
    <bib:Article rdf:about="#item_16">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kolhatkar</foaf:surname>
                        <foaf:givenname>Varada</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wu</foaf:surname>
                        <foaf:givenname>Hanhan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_7"/>
        <dc:subject>corpus</dc:subject>
        <dc:subject>socc</dc:subject>
        <bib:pages>31</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>The SFU Opinion and Comments Corpus: A Corpus for the Analysis of Online News Comments</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_7">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kolhatkar and Wu - The SFU Opinion and Comments Corpus A Corpus for .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/W17-3002">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:identifier>DOI 10.18653/v1/W17-3002</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kolhatkar</foaf:surname>
                        <foaf:givenname>Varada</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taboada</foaf:surname>
                        <foaf:givenname>Maite</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_6"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/W17-3002</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>11-17</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-07-25 15:15:48</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We discuss the characteristics of constructive news comments, and present methods to identify them. First, we deﬁne the notion of constructiveness. Second, we annotate a corpus for constructiveness. Third, we explore whether available argumentation corpora can be useful to identify constructiveness in news comments. Our model trained on argumentation corpora achieves a top accuracy of 72.59% (baseline=49.44%) on our crowdannotated test data. Finally, we examine the relation between constructiveness and toxicity. In our crowd-annotated data, 21.42% of the non-constructive comments and 17.89% of the constructive comments are toxic, suggesting that non-constructive comments are not much more toxic than constructive comments.</dcterms:abstract>
        <dc:title>Constructive Language in News Comments</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_6">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kolhatkar and Taboada - 2017 - Constructive Language in News Comments.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-3362-7">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-3362-7</dc:identifier>
                <dc:identifier>DOI 10.1145/2858036.2858389</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
           <foaf:Organization><foaf:name>ACM Press</foaf:name></foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Park</foaf:surname>
                        <foaf:givenname>Deokgun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sachar</foaf:surname>
                        <foaf:givenname>Simranjit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Diakopoulos</foaf:surname>
                        <foaf:givenname>Nicholas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Elmqvist</foaf:surname>
                        <foaf:givenname>Niklas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_22"/>
        <link:link rdf:resource="#item_20"/>
        <dc:subject>background</dc:subject>
        <dc:subject>nodeep</dc:subject>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?doid=2858036.2858389</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1114-1125</bib:pages>
        <dc:date>2016</dc:date>
        <dcterms:dateSubmitted>2018-07-25 16:52:36</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online comments submitted by readers of news articles can provide valuable feedback and critique, personal views and perspectives, and opportunities for discussion. The varying quality of these comments necessitates that publishers remove the low quality ones, but there is also a growing awareness that by identifying and highlighting high quality contributions this can promote the general quality of the community. In this paper we take a user-centered design approach towards developing a system, CommentIQ, which supports comment moderators in interactively identifying high quality comments using a combination of comment analytic scores as well as visualizations and flexible UI components. We evaluated this system with professional comment moderators working at local and national news outlets and provide insights into the utility and appropriateness of features for journalistic tasks, as well as how the system may enable or transform journalistic practices around online comments.</dcterms:abstract>
        <dc:title>Supporting Comment Moderators in Identifying High Quality Online News Comments</dc:title>
    </rdf:Description>
    <bib:Memo rdf:about="#item_22">
        <rdf:value>&lt;p&gt;&quot;&lt;span style=&quot;font-size: 10.000000pt; font-family: 'TimesNewRomanPSMT';&quot;&gt;Through our evaluation we found that journalists (and journalism as a domain) require analytic solutions that place humans in a flexible sensemaking loop with the analytics. Visual analytics is thus a well-suited approach for design in this domain. Journalists do not want editorial decisions automatically made for them per se, but rather seek designs that enable and enhance their own decision-making functions so that they can adapt to new situations and contexts and apply human judgment to editorial decisions.&lt;/span&gt;&quot;&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_20">
        <z:itemType>attachment</z:itemType>
        <dc:title>Park et al. - 2016 - Supporting Comment Moderators in Identifying High .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_25">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
    </bib:Article>
    <bib:Article rdf:about="http://arxiv.org/abs/1805.03668">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1805.03668 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Qin</foaf:surname>
                        <foaf:givenname>Lianhui</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Lemao</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bi</foaf:surname>
                        <foaf:givenname>Victoria</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Yan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Xiaojiang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hu</foaf:surname>
                        <foaf:givenname>Zhiting</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhao</foaf:surname>
                        <foaf:givenname>Hai</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shi</foaf:surname>
                        <foaf:givenname>Shuming</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_28"/>
        <link:link rdf:resource="#item_26"/>
        <dc:subject>corpus</dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1805.03668</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-05-09</dc:date>
        <dc:description>arXiv: 1805.03668</dc:description>
        <dcterms:dateSubmitted>2018-09-05 13:24:36</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Comments of online articles provide extended views and improve user engagement. Automatically making comments thus become a valuable functionality for online forums, intelligent chatbots, etc. This paper proposes the new task of automatic article commenting, and introduces a large-scale Chinese dataset1 with millions of real comments and a humanannotated subset characterizing the comments’ varying quality. Incorporating the human bias of comment quality, we further develop automatic metrics that generalize a broad set of popular reference-based metrics and exhibit greatly improved correlations with human evaluations.</dcterms:abstract>
        <dc:title>Automatic Article Commenting: the Task and Dataset</dc:title>
        <z:shortTitle>Automatic Article Commenting</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_28">
        <rdf:value>&lt;p&gt;Comment: ACL2018; with supplements; Dataset link available in the paper&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Chinese&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_26">
        <z:itemType>attachment</z:itemType>
        <dc:title>Qin et al. - 2018 - Automatic Article Commenting the Task and Dataset.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_30">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schabus</foaf:surname>
                        <foaf:givenname>Dietmar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Skowron</foaf:surname>
                        <foaf:givenname>Marcin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_29"/>
        <bib:pages>4</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>This paper describes an approach and our experiences from the development, deployment and usability testing of a Natural Language Processing (NLP) and Information Retrieval system that supports the moderation of user comments on a large newspaper website. We highlight some of the differences between industry-oriented and academic research settings and their inﬂuence on the decisions made in the data collection and annotation processes, selection of document representation and machine learning methods. We report on classiﬁcation results, where the problems to solve and the data to work with come from a commercial enterprise. In this context typical for NLP research, we discuss relevant industrial aspects. We believe that the challenges faced as well as the solutions proposed for addressing them can provide insights to others working in a similar setting. Data and experiment code related to this paper are available for download at https://ofai.github.io/million-post-corpus.</dcterms:abstract>
        <dc:title>Academic-Industrial Perspective on the Development and Deployment of a Moderation System for a Newspaper Website</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_29">
        <z:itemType>attachment</z:itemType>
        <dc:title>Schabus and Skowron - Academic-Industrial Perspective on the Development.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-5022-8">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-5022-8</dc:identifier>
                <dc:identifier>DOI 10.1145/3077136.3080711</dc:identifier>
                <dc:title>Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval  - SIGIR '17</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Shinjuku, Tokyo, Japan</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schabus</foaf:surname>
                        <foaf:givenname>Dietmar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Skowron</foaf:surname>
                        <foaf:givenname>Marcin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Trapp</foaf:surname>
                        <foaf:givenname>Martin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_31"/>
        <dc:subject>corpus</dc:subject>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?doid=3077136.3080711</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1241-1244</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-09-05 13:37:16</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the 40th International ACM SIGIR Conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>In this paper we introduce a new data set consisting of user comments posted to the website of a German-language Austrian newspaper. Professional forum moderators have annotated 11,773 posts according to seven categories they considered crucial for the efficient moderation of online discussions in the context of news articles. In addition to this taxonomy and annotated posts, the data set contains one million unlabeled posts. Our experimental results using six methods establish a first baseline for predicting these categories. The data and our code are available for research purposes from https://ofai.github.io/million-post-corpus.</dcterms:abstract>
        <dc:title>One Million Posts: A Data Set of German Online Discussions</dc:title>
        <z:shortTitle>One Million Posts</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_31">
        <z:itemType>attachment</z:itemType>
        <dc:title>Schabus et al. - 2017 - One Million Posts A Data Set of German Online Dis.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1702.05638">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1702.05638 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Potthast</foaf:surname>
                        <foaf:givenname>Martin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kiesel</foaf:surname>
                        <foaf:givenname>Johannes</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reinartz</foaf:surname>
                        <foaf:givenname>Kevin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bevendorff</foaf:surname>
                        <foaf:givenname>Janek</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stein</foaf:surname>
                        <foaf:givenname>Benno</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_35"/>
        <link:link rdf:resource="#item_33"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1702.05638</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-02-18</dc:date>
        <dc:description>arXiv: 1702.05638</dc:description>
        <dcterms:dateSubmitted>2018-09-05 13:44:58</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>This paper reports on a writing style analysis of hyperpartisan (i.e., extremely onesided) news in connection to fake news. It presents a large corpus of 1,627 articles that were manually fact-checked by professional journalists from BuzzFeed. The articles originated from 9 well-known political publishers, 3 each from the mainstream, the hyperpartisan left-wing, and the hyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of which originated from hyperpartisan publishers.</dcterms:abstract>
        <dc:title>A Stylometric Inquiry into Hyperpartisan and Fake News</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_35">
        <rdf:value>Comment: 10 pages, 3 figures, 6 tables, submitted to ACL 2017</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_33">
        <z:itemType>attachment</z:itemType>
        <dc:title>Potthast et al. - 2017 - A Stylometric Inquiry into Hyperpartisan and Fake .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://www.nomos-elibrary.de/index.php?doi=10.5771/2192-4007-2017-4-333">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:2192-4007"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loosen</foaf:surname>
                        <foaf:givenname>Wiebke</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Häring</foaf:surname>
                        <foaf:givenname>Marlo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kurtanović</foaf:surname>
                        <foaf:givenname>Zijad</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Merten</foaf:surname>
                        <foaf:givenname>Lisa</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reimer</foaf:surname>
                        <foaf:givenname>Julius</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roessel</foaf:surname>
                        <foaf:givenname>Lies van</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Maalej</foaf:surname>
                        <foaf:givenname>Walid</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_36"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.nomos-elibrary.de/index.php?doi=10.5771/2192-4007-2017-4-333</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>333-364</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-09-05 14:05:28</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Newsrooms are still searching for ways to manage user comments because of both a desire for professional distance from their audiences and a lack of analytical tools. This paper presents findings from our exploratory, interdisciplinary study in journalism research and computer science that focuses on the algorithmic classification and clustering of user comments. In contrast to endeavours that aim at filtering out hate speech or spam, we take a more constructive approach and focus on detecting particularly useful or highquality user contributions that can be leveraged for journalistic purposes. On the basis of a literature review and our own preliminary research on audience participation and user review analytics, we developed a mock-up of a software framework to help journalists systematically analyze user comments to this end. We then surveyed its effectiveness through two group discussions – one with comment moderators and another with editors from different editorial departments of a large German online newsroom. Features that journalists and comment moderators considered useful include the categorization of user comments in pro- and contra-arguments towards a certain topic, the automated assessment of comments' quality as well as the identification of surprising or exceptional comments and those that present new questions, arguments or viewpoints.</dcterms:abstract>
        <dc:title>Making sense of user comments: Identifying journalists’ requirements for a comment analysis framework</dc:title>
        <z:shortTitle>Making sense of user comments</z:shortTitle>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:2192-4007">
        <prism:volume>6</prism:volume>
        <prism:number>4</prism:number>
        <dc:title>Studies in Communication | Media</dc:title>
        <dc:identifier>ISSN 2192-4007</dc:identifier>
        <dc:identifier>DOI 10.5771/2192-4007-2017-4-333</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_36">
        <z:itemType>attachment</z:itemType>
        <dc:title>Loosen et al. - 2017 - Making sense of user comments Identifying journal.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_39">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mcmillen</foaf:surname>
                        <foaf:givenname>Suzanne R</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_38"/>
        <bib:pages>92</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Threads of Deliberation: A Textual Analysis of Online News Comments</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_38">
        <z:itemType>attachment</z:itemType>
        <dc:title>Mcmillen - Threads of Deliberation A Textual Analysis of Onl.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_41">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Amunategui</foaf:surname>
                        <foaf:givenname>Manuel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_40"/>
        <bib:pages>52</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Single-Pass, Adaptive Natural Language Filtering: Measuring Value in User Generated Comments on Large-Scale, Social Media News Forums</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_40">
        <z:itemType>attachment</z:itemType>
        <dc:title>Amunategui - Single-Pass, Adaptive Natural Language Filtering .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <z:Attachment rdf:about="#item_42">
        <z:itemType>attachment</z:itemType>
        <dc:title>ISOJ_Journal_V2_N1_2012_Spring.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="#item_44">
        <z:itemType>document</z:itemType>
        <link:link rdf:resource="#item_43"/>
        <dc:title>Comments in News, Democracy booster or Journalistic Nightmare: Assessing the Quality and Dynamics of Citizen Debates in Catalan Online Newspapers</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_43">
        <z:itemType>attachment</z:itemType>
        <dc:title>ISOJ_Journal_V2_N1_2012_Spring.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-0556-3">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-0556-3</dc:identifier>
                <dc:identifier>DOI 10.1145/1958824.1958844</dc:identifier>
                <dc:title>Proceedings of the ACM 2011 conference on Computer supported cooperative work - CSCW '11</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hangzhou, China</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Diakopoulos</foaf:surname>
                        <foaf:givenname>Nicholas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Naaman</foaf:surname>
                        <foaf:givenname>Mor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_45"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://portal.acm.org/citation.cfm?doid=1958824.1958844</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>133</bib:pages>
        <dc:date>2011</dc:date>
        <dcterms:dateSubmitted>2018-09-06 12:53:36</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the ACM 2011 conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>With the growth in sociality and interaction around online news media, news sites are increasingly becoming places for communities to discuss and address common issues spurred by news articles. The quality of online news comments is of importance to news organizations that want to provide a valuable exchange of community ideas and maintain credibility within the community. In this work we examine the complex interplay between the needs and desires of news commenters with the functioning of different journalistic approaches toward managing comment quality. Drawing primarily on newsroom interviews and reader surveys, we characterize the comment discourse of SacBee.com, discuss the relationship of comment quality to both the consumption and production of news information, and provide a description of both readers’ and writers’ motivations for usage of news comments. We also examine newsroom strategies for dealing with comment quality as well as explore tensions and opportunities for valuesensitive innovation within such online communities.</dcterms:abstract>
        <dc:title>Towards quality discourse in online news comments</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_45">
        <z:itemType>attachment</z:itemType>
        <dc:title>Diakopoulos and Naaman - 2011 - Towards quality discourse in online news comments.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_48">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <prism:volume>6</prism:volume>
                <prism:number>4</prism:number>
                <dc:title>Studies in Communication | Media</dc:title>
                <dc:identifier>ISSN 2192-4007</dc:identifier>
                <dc:identifier>DOI 10.5771/2192-4007-2017-4-333</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loosen</foaf:surname>
                        <foaf:givenname>Wiebke</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Häring</foaf:surname>
                        <foaf:givenname>Marlo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kurtanović</foaf:surname>
                        <foaf:givenname>Zijad</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Merten</foaf:surname>
                        <foaf:givenname>Lisa</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Reimer</foaf:surname>
                        <foaf:givenname>Julius</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roessel</foaf:surname>
                        <foaf:givenname>Lies van</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Maalej</foaf:surname>
                        <foaf:givenname>Walid</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_47"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.nomos-elibrary.de/index.php?doi=10.5771/2192-4007-2017-4-333</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>333-364</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-09-06 12:58:49</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Newsrooms are still searching for ways to manage user comments because of both a desire for professional distance from their audiences and a lack of analytical tools. This paper presents findings from our exploratory, interdisciplinary study in journalism research and computer science that focuses on the algorithmic classification and clustering of user comments. In contrast to endeavours that aim at filtering out hate speech or spam, we take a more constructive approach and focus on detecting particularly useful or highquality user contributions that can be leveraged for journalistic purposes. On the basis of a literature review and our own preliminary research on audience participation and user review analytics, we developed a mock-up of a software framework to help journalists systematically analyze user comments to this end. We then surveyed its effectiveness through two group discussions – one with comment moderators and another with editors from different editorial departments of a large German online newsroom. Features that journalists and comment moderators considered useful include the categorization of user comments in pro- and contra-arguments towards a certain topic, the automated assessment of comments' quality as well as the identification of surprising or exceptional comments and those that present new questions, arguments or viewpoints.</dcterms:abstract>
        <dc:title>Making sense of user comments: Identifying journalists’ requirements for a comment analysis framework</dc:title>
        <z:shortTitle>Making sense of user comments</z:shortTitle>
    </bib:Article>
    <z:Attachment rdf:about="#item_47">
        <z:itemType>attachment</z:itemType>
        <dc:title>Loosen et al. - 2017 - Making sense of user comments Identifying journal.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_50">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Llewellyn</foaf:surname>
                        <foaf:givenname>Clare</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Grover</foaf:surname>
                        <foaf:givenname>Claire</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Oberlander</foaf:surname>
                        <foaf:givenname>Jon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_49"/>
        <bib:pages>4</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>This work investigates summarizing the conversations that occur in the comments section of the UK newspaper the Guardian. In the comment summarization task comments are clustered and ranked within the cluster. The top comments from each cluster are used to give an overview of that cluster. It was found that topic model clustering gave the most agreement when evaluated against a human gold standard. This approach is compared to cosine distance clustering and k-means clustering. PageRank was found to be the prefered ranking system when compared with TF-IDF, Mutual Information gain and Maximal Marginal Relevance and evaluated against sets of comments summarized by a journalist for the Guardian letters page.</dcterms:abstract>
        <dc:title>Summarizing Newspaper Comments</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_49">
        <z:itemType>attachment</z:itemType>
        <dc:title>Llewellyn et al. - Summarizing Newspaper Comments.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1703.04009">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1703.04009 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Davidson</foaf:surname>
                        <foaf:givenname>Thomas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Warmsley</foaf:surname>
                        <foaf:givenname>Dana</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Macy</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weber</foaf:surname>
                        <foaf:givenname>Ingmar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_53"/>
        <link:link rdf:resource="#item_51"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1703.04009</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-03-11</dc:date>
        <dc:description>arXiv: 1703.04009</dc:description>
        <dcterms:dateSubmitted>2018-09-06 15:05:13</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classiﬁer to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difﬁcult. We ﬁnd that racist and homophobic tweets are more likely to be classiﬁed as hate speech but that sexist tweets are generally classiﬁed as offensive. Tweets without explicit hate keywords are also more difﬁcult to classify.</dcterms:abstract>
        <dc:title>Automated Hate Speech Detection and the Problem of Offensive Language</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_53">
        <rdf:value>Comment: To appear in the Proceedings of ICWSM 2017. Please cite that version</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_51">
        <z:itemType>attachment</z:itemType>
        <dc:title>Davidson et al. - 2017 - Automated Hate Speech Detection and the Problem of.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_55">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Risch</foaf:surname>
                        <foaf:givenname>Julian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krestel</foaf:surname>
                        <foaf:givenname>Ralf</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_54"/>
        <bib:pages>11</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Comment sections of online news providers have enabled millions to share and discuss their opinions on news topics. Today, moderators ensure respectful and informative discussions by deleting not only insults, defamation, and hate speech, but also unveriﬁable facts. This process has to be transparent and comprehensive in order to keep the community engaged. Further, news providers have to make sure to not give the impression of censorship or dissemination of fake news. Yet manual moderation is very expensive and becomes more and more unfeasible with the increasing amount of comments. Hence, we propose a semi-automatic, holistic approach, which includes comment features but also their context, such as information about users and articles. For evaluation, we present experiments on a novel corpus of 3 million news comments annotated by a team of professional moderators.</dcterms:abstract>
        <dc:title>Delete or not Delete? Semi-Automatic Comment Moderation for the Newsroom</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_54">
        <z:itemType>attachment</z:itemType>
        <dc:title>Risch and Krestel - Delete or not Delete Semi-Automatic Comment Moder.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-4143-1">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-4143-1</dc:identifier>
                <dc:identifier>DOI 10.1145/2872427.2883062</dc:identifier>
                <dc:title>Proceedings of the 25th International Conference on World Wide Web - WWW '16</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Montr&amp;#233;al, Qu&amp;#233;bec, Canada</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nobata</foaf:surname>
                        <foaf:givenname>Chikashi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tetreault</foaf:surname>
                        <foaf:givenname>Joel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Thomas</foaf:surname>
                        <foaf:givenname>Achint</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mehdad</foaf:surname>
                        <foaf:givenname>Yashar</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chang</foaf:surname>
                        <foaf:givenname>Yi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_56"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?doid=2872427.2883062</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>145-153</bib:pages>
        <dc:date>2016</dc:date>
        <dcterms:dateSubmitted>2018-09-06 15:07:55</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the 25th International Conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Detection of abusive language in user generated online content has become an issue of increasing importance in recent years. Most current commercial methods make use of blacklists and regular expressions, however these measures fall short when contending with more subtle, less ham-ﬁsted examples of hate speech. In this work, we develop a machine learning based method to detect hate speech on online user comments from two domains which outperforms a state-ofthe-art deep learning approach. We also develop a corpus of user comments annotated for abusive language, the ﬁrst of its kind. Finally, we use our detection tool to analyze abusive language over time and in diﬀerent settings to further enhance our knowledge of this behavior.</dcterms:abstract>
        <dc:title>Abusive Language Detection in Online User Content</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_56">
        <z:itemType>attachment</z:itemType>
        <dc:title>Nobata et al. - 2016 - Abusive Language Detection in Online User Content.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-58113-702-6">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-58113-702-6</dc:identifier>
                <dc:identifier>DOI 10.1145/985692.985761</dc:identifier>
                <dc:title>Proceedings of the 2004 conference on Human factors in computing systems  - CHI '04</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Vienna, Austria</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lampe</foaf:surname>
                        <foaf:givenname>Cliff</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Resnick</foaf:surname>
                        <foaf:givenname>Paul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_58"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://portal.acm.org/citation.cfm?doid=985692.985761</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>543-550</bib:pages>
        <dc:date>2004</dc:date>
        <dcterms:dateSubmitted>2018-09-07 08:22:43</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the 2004 conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Can a system of distributed moderation quickly and consistently separate high and low quality comments in an online conversation? Analysis of the site Slashdot.org suggests that the answer is a qualified yes, but that important challenges remain for designers of such systems. Thousands of users act as moderators. Final scores for comments are reasonably dispersed and the community generally agrees that moderations are fair. On the other hand, much of a conversation can pass before the best and worst comments are identified. Of those moderations that were judged unfair, only about half were subsequently counterbalanced by a moderation in the other direction. And comments with low scores, not at top-level, or posted late in a conversation were more likely to be overlooked by moderators.</dcterms:abstract>
        <dc:title>Slash(dot) and burn: distributed moderation in a large online conversation space</dc:title>
        <z:shortTitle>Slash(dot) and burn</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_58">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lampe and Resnick - 2004 - Slash(dot) and burn distributed moderation in a l.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-60558-085-2">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-60558-085-2</dc:identifier>
                <dc:identifier>DOI 10.1145/1367497.1367585</dc:identifier>
                <dc:title>Proceeding of the 17th international conference on World Wide Web  - WWW '08</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing, China</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gómez</foaf:surname>
                        <foaf:givenname>Vicenç</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kaltenbrunner</foaf:surname>
                        <foaf:givenname>Andreas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>López</foaf:surname>
                        <foaf:givenname>Vicente</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_60"/>
        <dc:subject>threads</dc:subject>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://portal.acm.org/citation.cfm?doid=1367497.1367585</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>645</bib:pages>
        <dc:date>2008</dc:date>
        <dcterms:dateSubmitted>2018-09-07 08:23:58</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceeding of the 17th international conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>We analyze the social network emerging from the user comment activity on the website Slashdot. The network presents common features of traditional social networks such as a giant component, small average path length and high clustering, but diﬀers from them showing moderate reciprocity and neutral assortativity by degree. Using Kolmogorov-Smirnov statistical tests, we show that the degree distributions are better explained by log-normal instead of power-law distributions. We also study the structure of discussion threads using an intuitive radial tree representation. Threads show strong heterogeneity and self-similarity throughout the different nesting levels of a conversation. We use these results to propose a simple measure to evaluate the degree of controversy provoked by a post.</dcterms:abstract>
        <dc:title>Statistical analysis of the social network and discussion threads in slashdot</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_60">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gómez et al. - 2008 - Statistical analysis of the social network and dis.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://portal.acm.org/citation.cfm?doid=1787234.1787254">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:00010782"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Szabo</foaf:surname>
                        <foaf:givenname>Gabor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Huberman</foaf:surname>
                        <foaf:givenname>Bernardo A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_62"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://portal.acm.org/citation.cfm?doid=1787234.1787254</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>80</bib:pages>
        <dc:date>2010-08-01</dc:date>
        <dcterms:dateSubmitted>2018-09-07 08:25:45</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Predicting the popularity of online content</dc:title>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:00010782">
        <prism:volume>53</prism:volume>
        <prism:number>8</prism:number>
        <dc:title>Communications of the ACM</dc:title>
        <dc:identifier>ISSN 00010782</dc:identifier>
        <dc:identifier>DOI 10.1145/1787234.1787254</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_62">
        <z:itemType>attachment</z:itemType>
        <dc:title>Szabo and Huberman - 2010 - Predicting the popularity of online content.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1808.07191">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1808.07191 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Deli</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ma</foaf:surname>
                        <foaf:givenname>Shuming</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yang</foaf:surname>
                        <foaf:givenname>Pengcheng</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sun</foaf:surname>
                        <foaf:givenname>Xu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_65"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1808.07191</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-08-21</dc:date>
        <dc:description>arXiv: 1808.07191</dc:description>
        <dcterms:dateSubmitted>2018-09-07 09:15:06</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>With the development of information technology, there is an explosive growth in the number of online comment concerning news, blogs and so on. The massive comments are overloaded, and often contain some misleading and unwelcome information. Therefore, it is necessary to identify high-quality comments and ﬁlter out low-quality comments. In this work, we introduce a novel task: high-quality comment identiﬁcation (HQCI), which aims to automatically assess the quality of online comments. First, we construct a news comment corpus, which consists of news, comments, and the corresponding quality label. Second, we analyze the dataset, and ﬁnd the quality of comments can be measured in three aspects: informativeness, consistency, and novelty. Finally, we propose a novel multi-target text matching model, which can measure three aspects by referring to the news and surrounding comments. Experimental results show that our method can outperform various baselines by a large margin on the news dataset.</dcterms:abstract>
        <dc:title>Identifying High-Quality Chinese News Comments Based on Multi-Target Text Matching Model</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_65">
        <z:itemType>attachment</z:itemType>
        <dc:title>Chen et al. - 2018 - Identifying High-Quality Chinese News Comments Bas.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1803.11175">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1803.11175 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cer</foaf:surname>
                        <foaf:givenname>Daniel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yang</foaf:surname>
                        <foaf:givenname>Yinfei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kong</foaf:surname>
                        <foaf:givenname>Sheng-yi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hua</foaf:surname>
                        <foaf:givenname>Nan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Limtiaco</foaf:surname>
                        <foaf:givenname>Nicole</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>John</foaf:surname>
                        <foaf:givenname>Rhomni St</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Constant</foaf:surname>
                        <foaf:givenname>Noah</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guajardo-Cespedes</foaf:surname>
                        <foaf:givenname>Mario</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yuan</foaf:surname>
                        <foaf:givenname>Steve</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tar</foaf:surname>
                        <foaf:givenname>Chris</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sung</foaf:surname>
                        <foaf:givenname>Yun-Hsuan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Strope</foaf:surname>
                        <foaf:givenname>Brian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kurzweil</foaf:surname>
                        <foaf:givenname>Ray</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_70"/>
        <link:link rdf:resource="#item_68"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1803.11175</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-03-29</dc:date>
        <dc:description>arXiv: 1803.11175</dc:description>
        <dcterms:dateSubmitted>2018-09-12 20:25:13</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We present models for encoding sentences into embedding vectors that speciﬁcally target transfer learning to other NLP tasks. The models are efﬁcient and result in accurate performance on diverse transfer tasks. Two variants of the encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and report the relationship between model complexity, resource consumption, the availability of transfer task training data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained word embeddings as well as baselines do not use any transfer learning. We ﬁnd that transfer learning using sentence embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained sentence encoding models are made freely available for download and on TF Hub.</dcterms:abstract>
        <dc:title>Universal Sentence Encoder</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_70">
       <rdf:value>Comment: 7 pages; fixed module URL in Listing 1</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_68">
        <z:itemType>attachment</z:itemType>
        <dc:title>Cer et al. - 2018 - Universal Sentence Encoder.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1801.06146">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv:1801.06146 [cs, stat]</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Howard</foaf:surname>
                        <foaf:givenname>Jeremy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ruder</foaf:surname>
                        <foaf:givenname>Sebastian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_73"/>
        <link:link rdf:resource="#item_71"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Statistics - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1801.06146</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-01-18</dc:date>
        <dc:description>arXiv: 1801.06146</dc:description>
        <dcterms:dateSubmitted>2018-09-12 20:28:31</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-speciﬁc modiﬁcations and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for ﬁne-tuning a language model. Our method signiﬁcantly outperforms the state-of-the-art on six text classiﬁcation tasks, reducing the error by 1824% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100× more data. We opensource our pretrained models and code1.</dcterms:abstract>
        <dc:title>Universal Language Model Fine-tuning for Text Classification</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_73">
        <rdf:value>Comment: ACL 2018, fixed denominator in Equation 3, line 3</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_71">
        <z:itemType>attachment</z:itemType>
        <dc:title>Howard and Ruder - 2018 - Universal Language Model Fine-tuning for Text Clas.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1806.06259">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1806.06259 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Perone</foaf:surname>
                        <foaf:givenname>Christian S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Silveira</foaf:surname>
                        <foaf:givenname>Roberto</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Paula</foaf:surname>
                        <foaf:givenname>Thomas S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_76"/>
        <link:link rdf:resource="#item_74"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1806.06259</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-06-16</dc:date>
        <dc:description>arXiv: 1806.06259</dc:description>
        <dcterms:dateSubmitted>2018-09-12 20:34:11</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Despite the fast developmental pace of new sentence embedding methods, it is still challenging to ﬁnd comprehensive evaluations of these different techniques. In the past years, we saw signiﬁcant improvements in the ﬁeld of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep contextdependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.</dcterms:abstract>
        <dc:title>Evaluation of sentence embeddings in downstream and linguistic probing tasks</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_76">
        <rdf:value>&lt;p&gt;Comment: 15 pages, 3 figures, 11 tables&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_74">
        <z:itemType>attachment</z:itemType>
        <dc:title>Perone et al. - 2018 - Evaluation of sentence embeddings in downstream an.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1705.02364">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1705.02364 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Conneau</foaf:surname>
                        <foaf:givenname>Alexis</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kiela</foaf:surname>
                        <foaf:givenname>Douwe</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schwenk</foaf:surname>
                        <foaf:givenname>Holger</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Barrault</foaf:surname>
                        <foaf:givenname>Loic</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bordes</foaf:surname>
                        <foaf:givenname>Antoine</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_81"/>
        <link:link rdf:resource="#item_79"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1705.02364</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-05-05</dc:date>
        <dc:description>arXiv: 1705.02364</dc:description>
        <dcterms:dateSubmitted>2018-09-12 20:44:56</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.</dcterms:abstract>
        <dc:title>Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_81">
       <rdf:value>Comment: EMNLP 2017</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_79">
        <z:itemType>attachment</z:itemType>
        <dc:title>Conneau et al. - 2017 - Supervised Learning of Universal Sentence Represen.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_83">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Radford</foaf:surname>
                        <foaf:givenname>Alec</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Narasimhan</foaf:surname>
                        <foaf:givenname>Karthik</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Salimans</foaf:surname>
                        <foaf:givenname>Tim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sutskever</foaf:surname>
                        <foaf:givenname>Ilya</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_82"/>
        <bib:pages>12</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).</dcterms:abstract>
        <dc:title>Improving Language Understanding by Generative Pre-Training</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_82">
        <z:itemType>attachment</z:itemType>
        <dc:title>Radford et al. - Improving Language Understanding by Generative Pre.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1806.05662">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv:1806.05662 [cs, stat]</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yang</foaf:surname>
                        <foaf:givenname>Zhilin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhao</foaf:surname>
                        <foaf:givenname>Jake</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dhingra</foaf:surname>
                        <foaf:givenname>Bhuwan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>He</foaf:surname>
                        <foaf:givenname>Kaiming</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cohen</foaf:surname>
                        <foaf:givenname>William W.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Salakhutdinov</foaf:surname>
                        <foaf:givenname>Ruslan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>LeCun</foaf:surname>
                        <foaf:givenname>Yann</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_84"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Statistics - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Computer Vision and Pattern Recognition</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1806.05662</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-06-14</dc:date>
        <dc:description>arXiv: 1806.05662</dc:description>
        <dcterms:dateSubmitted>2018-09-12 23:19:06</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classiﬁcation. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-speciﬁc RNN hidden units), or embedding-free units such as image pixels.</dcterms:abstract>
        <dc:title>GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations</dc:title>
        <z:shortTitle>GLoMo</z:shortTitle>
    </bib:Article>
    <z:Attachment rdf:about="#item_84">
        <z:itemType>attachment</z:itemType>
        <dc:title>Yang et al. - 2018 - GLoMo Unsupervisedly Learned Relational Graphs as.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_87">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Shuohang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jiang</foaf:surname>
                        <foaf:givenname>Jing</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_86"/>
        <bib:pages>11</bib:pages>
        <dc:date>2017</dc:date>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Many NLP tasks including machine comprehension, answer selection and text entailment require the comparison between sequences. Matching the important units between sequences is a key to solve these problems. In this paper, we present a general “compare-aggregate” framework that performs word-level matching followed by aggregation using Convolutional Neural Networks. We particularly focus on the different comparison functions we can use to match two vectors. We use four different datasets to evaluate the model. We ﬁnd that some simple comparison functions based on element-wise operations can work better than standard neural network and neural tensor network.</dcterms:abstract>
        <dc:title>A COMPARE-AGGREGATE MODEL FOR MATCHING TEXT SEQUENCES</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_86">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wang and Jiang - 2017 - A COMPARE-AGGREGATE MODEL FOR MATCHING TEXT SEQUEN.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1702.03814">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1702.03814 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Zhiguo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hamza</foaf:surname>
                        <foaf:givenname>Wael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Florian</foaf:surname>
                        <foaf:givenname>Radu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_93"/>
        <link:link rdf:resource="#item_88"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1702.03814</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-02-13</dc:date>
        <dc:description>arXiv: 1702.03814</dc:description>
        <dcterms:dateSubmitted>2018-09-16 13:18:38</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Natural language sentence matching is a fundamental technology for a variety of tasks. Previous approaches either match sentences from a single direction or only apply single granular (wordby-word or sentence-by-sentence) matching. In this work, we propose a bilateral multi-perspective matching (BiMPM) model. Given two sentences P and Q, our model ﬁrst encodes them with a BiLSTM encoder. Next, we match the two encoded sentences in two directions P against Q and Q against P . In each matching direction, each time step of one sentence is matched against all timesteps of the other sentence from multiple perspectives. Then, another BiLSTM layer is utilized to aggregate the matching results into a ﬁxed-length matching vector. Finally, based on the matching vector, a decision is made through a fully connected layer. We evaluate our model on three tasks: paraphrase identiﬁcation, natural language inference and answer sentence selection. Experimental results on standard benchmark datasets show that our model achieves the state-of-the-art performance on all tasks.</dcterms:abstract>
        <dc:title>Bilateral Multi-Perspective Matching for Natural Language Sentences</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_93">
       <rdf:value>Comment: To appear in Proceedings of IJCAI 2017</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_88">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wang et al. - 2017 - Bilateral Multi-Perspective Matching for Natural L.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1711.04289">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1711.04289 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Qian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhu</foaf:surname>
                        <foaf:givenname>Xiaodan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ling</foaf:surname>
                        <foaf:givenname>Zhen-Hua</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Inkpen</foaf:surname>
                        <foaf:givenname>Diana</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wei</foaf:surname>
                        <foaf:givenname>Si</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_95"/>
        <link:link rdf:resource="#item_91"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1711.04289</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-11-12</dc:date>
        <dc:description>arXiv: 1711.04289</dc:description>
        <dcterms:dateSubmitted>2018-09-16 13:18:42</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex models such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference (NLI) from these data? If not, how can neural-network-based NLI models beneﬁt from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets.</dcterms:abstract>
        <dc:title>Neural Natural Language Inference Models Enhanced with External Knowledge</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_95">
       <rdf:value>Comment: Accepted by ACL 2018</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_91">
        <z:itemType>attachment</z:itemType>
        <dc:title>Chen et al. - 2017 - Neural Natural Language Inference Models Enhanced .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1709.07109">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv:1709.07109 [cs, stat]</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shen</foaf:surname>
                        <foaf:givenname>Dinghan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhang</foaf:surname>
                        <foaf:givenname>Yizhe</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Henao</foaf:surname>
                        <foaf:givenname>Ricardo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Su</foaf:surname>
                        <foaf:givenname>Qinliang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Carin</foaf:surname>
                        <foaf:givenname>Lawrence</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_97"/>
        <link:link rdf:resource="#item_90"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Statistics - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1709.07109</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-09-20</dc:date>
        <dc:description>arXiv: 1709.07109</dc:description>
        <dcterms:dateSubmitted>2018-09-16 13:18:48</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>A latent-variable model is introduced for text matching, inferring sentence representations by jointly optimizing generative and discriminative objectives. To alleviate typical optimization challenges in latent-variable models for text, we employ deconvolutional networks as the sequence decoder (generator), providing learned latent codes with more semantic information and better generalization. Our model, trained in an unsupervised manner, yields stronger empirical predictive performance than a decoder based on Long Short-Term Memory (LSTM), with less parameters and considerably faster training. Further, we apply it to text sequence-matching problems. The proposed model signiﬁcantly outperforms several strong sentence-encoding baselines, especially in the semisupervised setting.</dcterms:abstract>
        <dc:title>Deconvolutional Latent-Variable Model for Text Sequence Matching</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_97">
       <rdf:value>Comment: Accepted by AAAI-2018</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_90">
        <z:itemType>attachment</z:itemType>
        <dc:title>Shen et al. - 2017 - Deconvolutional Latent-Variable Model for Text Seq.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_98">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hu</foaf:surname>
                        <foaf:givenname>Baotian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lu</foaf:surname>
                        <foaf:givenname>Zhengdong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenname>Hang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Qingcai</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_89"/>
        <bib:pages>9</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Semantic matching is of central importance to many natural language tasks [2, 28]. A successful matching algorithm needs to adequately model the internal structures of language objects and the interaction between them. As a step toward this goal, we propose convolutional neural network models for matching two sentences, by adapting the convolutional strategy in vision and speech. The proposed models not only nicely represent the hierarchical structures of sentences with their layerby-layer composition and pooling, but also capture the rich matching patterns at different levels. Our models are rather generic, requiring no prior knowledge on language, and can hence be applied to matching tasks of different nature and in different languages. The empirical study on a variety of matching tasks demonstrates the efﬁcacy of the proposed model on a variety of matching tasks and its superiority to competitor models.</dcterms:abstract>
        <dc:title>Convolutional Neural Network Architectures for Matching Natural Language Sentences</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_89">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hu et al. - Convolutional Neural Network Architectures for Mat.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1805.04869">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1805.04869 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ma</foaf:surname>
                        <foaf:givenname>Shuming</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sun</foaf:surname>
                        <foaf:givenname>Xu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Junyang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Houfeng</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_101"/>
        <link:link rdf:resource="#item_99"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1805.04869</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-05-13</dc:date>
        <dc:description>arXiv: 1805.04869</dc:description>
        <dcterms:dateSubmitted>2018-09-16 13:20:19</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Most of the current abstractive text summarization models are based on the sequence-to-sequence model (Seq2Seq). The source content of social media is long and noisy, so it is difficult for Seq2Seq to learn an accurate semantic representation. Compared with the source content, the annotated summary is short and well written. Moreover, it shares the same meaning as the source content. In this work, we supervise the learning of the representation of the source content with that of the summary. In implementation, we regard a summary autoencoder as an assistant supervisor of Seq2Seq. Following previous work, we evaluate our model on a popular Chinese social media dataset. Experimental results show that our model achieves the state-of-the-art performances on the benchmark dataset.</dcterms:abstract>
        <dc:title>Autoencoder as Assistant Supervisor: Improving Text Representation for Chinese Social Media Text Summarization</dc:title>
        <z:shortTitle>Autoencoder as Assistant Supervisor</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_101">
       <rdf:value>Comment: accepted by ACL 2018</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_99">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ma et al. - 2018 - Autoencoder as Assistant Supervisor Improving Tex.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1803.00179">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>Proceedings of the 2018 World Wide Web Conference on World Wide Web  - WWW '18</dc:title>
                <dc:identifier>DOI 10.1145/3178876.3186022</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Bang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhang</foaf:surname>
                        <foaf:givenname>Ting</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Han</foaf:surname>
                        <foaf:givenname>Fred X.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Niu</foaf:surname>
                        <foaf:givenname>Di</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lai</foaf:surname>
                        <foaf:givenname>Kunfeng</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xu</foaf:surname>
                        <foaf:givenname>Yu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_104"/>
        <link:link rdf:resource="#item_102"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1803.00179</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1237-1246</bib:pages>
        <dc:date>2018</dc:date>
        <dc:description>arXiv: 1803.00179</dc:description>
        <dcterms:dateSubmitted>2018-09-16 13:31:51</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Semantic matching of natural language sentences or identifying the relationship between two sentences is a core research problem underlying many natural language tasks. Depending on whether training data is available, prior research has proposed both unsupervised distance-based schemes and supervised deep learning schemes for sentence matching. However, previous approaches either omit or fail to fully utilize the ordered, hierarchical, and flexible structures of language objects, as well as the interactions between them. In this paper, we propose Hierarchical Sentence Factorization—a technique to factorize a sentence into a hierarchical representation, with the components at each different scale reordered into a “predicate-argument” form. The proposed sentence factorization technique leads to the invention of: 1) a new unsupervised distance metric which calculates the semantic distance between a pair of text snippets by solving a penalized optimal transport problem while preserving the logical relationship of words in the reordered sentences, and 2) new multi-scale deep learning models for supervised semantic training, based on factorized sentence hierarchies. We apply our techniques to text-pair similarity estimation and text-pair relationship classification tasks, based on multiple datasets such as STSbenchmark, the Microsoft Research paraphrase identification (MSRP) dataset, the SICK dataset, etc. Extensive experiments show that the proposed hierarchical sentence factorization can be used to significantly improve the performance of existing unsupervised distance-based metrics as well as multiple supervised deep learning models based on the convolutional neural network (CNN) and long short-term memory (LSTM).</dcterms:abstract>
        <dc:title>Matching Natural Language Sentences with Hierarchical Sentence Factorization</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_104">
       <rdf:value>Comment: Accepted by WWW 2018, 10 pages</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_102">
        <z:itemType>attachment</z:itemType>
        <dc:title>Liu et al. - 2018 - Matching Natural Language Sentences with Hierarchi.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1806.02847">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1806.02847 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Trinh</foaf:surname>
                        <foaf:givenname>Trieu H.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Le</foaf:surname>
                        <foaf:givenname>Quoc V.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_108"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1806.02847</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-06-07</dc:date>
        <dc:description>arXiv: 1806.02847</dc:description>
        <dcterms:dateSubmitted>2018-09-16 18:50:23</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Commonsense reasoning is a long-standing challenge for deep learning. For example, it is difﬁcult to use neural networks to tackle the Winograd Schema dataset [1]. In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.</dcterms:abstract>
        <dc:title>A Simple Method for Commonsense Reasoning</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_108">
        <z:itemType>attachment</z:itemType>
        <dc:title>Trinh and Le - 2018 - A Simple Method for Commonsense Reasoning.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1301.3781">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1301.3781 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mikolov</foaf:surname>
                        <foaf:givenname>Tomas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Kai</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Corrado</foaf:surname>
                        <foaf:givenname>Greg</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dean</foaf:surname>
                        <foaf:givenname>Jeffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_114"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1301.3781</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2013-01-16</dc:date>
        <dc:description>arXiv: 1301.3781</dc:description>
        <dcterms:dateSubmitted>2018-09-16 22:47:50</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.</dcterms:abstract>
        <dc:title>Efficient Estimation of Word Representations in Vector Space</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_114">
        <z:itemType>attachment</z:itemType>
        <dc:title>Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/D14-1162">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.3115/v1/D14-1162</dc:identifier>
                <dc:title>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Doha, Qatar</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pennington</foaf:surname>
                        <foaf:givenname>Jeffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Socher</foaf:surname>
                        <foaf:givenname>Richard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Manning</foaf:surname>
                        <foaf:givenname>Christopher</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_116"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/D14-1162</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1532-1543</bib:pages>
        <dc:date>2014</dc:date>
        <dcterms:dateSubmitted>2018-09-17 11:19:22</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Recent methods for learning vector space representations of words have succeeded in capturing ﬁne-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efﬁciently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.</dcterms:abstract>
        <dc:title>Glove: Global Vectors for Word Representation</dc:title>
        <z:shortTitle>Glove</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_116">
        <z:itemType>attachment</z:itemType>
        <dc:title>Pennington et al. - 2014 - Glove Global Vectors for Word Representation.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1607.04606">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1607.04606 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bojanowski</foaf:surname>
                        <foaf:givenname>Piotr</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Grave</foaf:surname>
                        <foaf:givenname>Edouard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Joulin</foaf:surname>
                        <foaf:givenname>Armand</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mikolov</foaf:surname>
                        <foaf:givenname>Tomas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_120"/>
        <link:link rdf:resource="#item_118"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1607.04606</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2016-07-15</dc:date>
        <dc:description>arXiv: 1607.04606</dc:description>
        <dcterms:dateSubmitted>2018-09-17 11:22:22</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.</dcterms:abstract>
        <dc:title>Enriching Word Vectors with Subword Information</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_120">
        <rdf:value>Comment: Accepted to TACL. The two first authors contributed equally</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_118">
        <z:itemType>attachment</z:itemType>
        <dc:title>Bojanowski et al. - 2016 - Enriching Word Vectors with Subword Information.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="#item_125">
        <z:itemType>document</z:itemType>
        <link:link rdf:resource="#item_124"/>
        <dc:title>Long Short-term Memory</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_124">
        <z:itemType>attachment</z:itemType>
        <dc:title>lstm.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1805.10369">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv:1805.10369 [cs, stat]</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miller</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hardt</foaf:surname>
                        <foaf:givenname>Moritz</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_126"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Statistics - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1805.10369</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-05-25</dc:date>
        <dc:description>arXiv: 1805.10369</dc:description>
        <dcterms:dateSubmitted>2018-09-18 15:48:22</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent. Our result applies to a broad range of non-linear recurrent neural networks under a natural stability condition, which we observe is also necessary. Complementing our theoretical ﬁndings, we verify the conclusions of our theory on both real and synthetic tasks. Furthermore, we demonstrate recurrent models satisfying the stability assumption of our theory can have excellent performance on real sequence learning tasks.</dcterms:abstract>
        <dc:title>When Recurrent Models Don't Need To Be Recurrent</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_126">
        <z:itemType>attachment</z:itemType>
        <dc:title>Miller and Hardt - 2018 - When Recurrent Models Don't Need To Be Recurrent.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_129">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Akbik</foaf:surname>
                        <foaf:givenname>Alan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Blythe</foaf:surname>
                        <foaf:givenname>Duncan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Vollgraf</foaf:surname>
                        <foaf:givenname>Roland</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_128"/>
        <bib:pages>12</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and ﬁnd that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we signiﬁcantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CONLL03 shared task.</dcterms:abstract>
        <dc:title>Contextual String Embeddings for Sequence Labeling</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_128">
        <z:itemType>attachment</z:itemType>
        <dc:title>Akbik et al. - Contextual String Embeddings for Sequence Labeling.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_131">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_130"/>
        <bib:pages>309</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Neural Network Methods for Natural Language Processing</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_130">
        <z:itemType>attachment</z:itemType>
        <dc:title>Neural Network Methods for Natural Language Processing</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/S17-2083">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/S17-2083</dc:identifier>
                <dc:title>Proceedings of the 11th International Workshop on Semantic Evaluation           (SemEval-2017)</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Vancouver, Canada</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kochkina</foaf:surname>
                        <foaf:givenname>Elena</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liakata</foaf:surname>
                        <foaf:givenname>Maria</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Augenstein</foaf:surname>
                        <foaf:givenname>Isabelle</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_132"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/S17-2083</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>475-480</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-09-19 10:20:33</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 11th International Workshop on Semantic Evaluation           (SemEval-2017)</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>This paper describes team Turing’s submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classiﬁcation, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classiﬁcation is considered to be an important step towards rumour veriﬁcation, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.</dcterms:abstract>
        <dc:title>Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM</dc:title>
        <z:shortTitle>Turing at SemEval-2017 Task 8</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_132">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kochkina et al. - 2017 - Turing at SemEval-2017 Task 8 Sequential Approach.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1708.02182">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1708.02182 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Merity</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Keskar</foaf:surname>
                        <foaf:givenname>Nitish Shirish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Socher</foaf:surname>
                        <foaf:givenname>Richard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_134"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Neural and Evolutionary Computing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1708.02182</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-08-07</dc:date>
        <dc:description>arXiv: 1708.02182</dc:description>
        <dcterms:dateSubmitted>2018-09-19 15:45:47</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Recurrent neural networks (RNNs), such as long short-term memory networks (LSTMs), serve as a fundamental building block for many sequence learning tasks, including machine translation, language modeling, and question answering. In this paper, we consider the speciﬁc problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTMbased models. We propose the weight-dropped LSTM which uses DropConnect on hidden-tohidden weights as a form of recurrent regularization. Further, we introduce NT-ASGD, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. Using these and other regularization strategies, we achieve state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2.</dcterms:abstract>
        <dc:title>Regularizing and Optimizing LSTM Language Models</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_134">
        <z:itemType>attachment</z:itemType>
        <dc:title>Merity et al. - 2017 - Regularizing and Optimizing LSTM Language Models.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_138">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1806.02847 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Trinh</foaf:surname>
                        <foaf:givenname>Trieu H.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Le</foaf:surname>
                        <foaf:givenname>Quoc V.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_137"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1806.02847</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-06-07</dc:date>
        <dc:description>arXiv: 1806.02847</dc:description>
        <dcterms:dateSubmitted>2018-09-23 21:24:58</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Commonsense reasoning is a long-standing challenge for deep learning. For example, it is difﬁcult to use neural networks to tackle the Winograd Schema dataset [1]. In this paper, we present a simple method for commonsense reasoning with neural networks, using unsupervised learning. Key to our method is the use of language models, trained on a massive amount of unlabled data, to score multiple choice questions posed by commonsense reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges, our models outperform previous state-of-the-art methods by a large margin, without using expensive annotated knowledge bases or hand-engineered features. We train an array of large RNN language models that operate at word or character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a customized corpus for this task and show that diversity of training data plays an important role in test performance. Further analysis also shows that our system successfully discovers important features of the context that decide the correct answer, indicating a good grasp of commonsense knowledge.</dcterms:abstract>
        <dc:title>A Simple Method for Commonsense Reasoning</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_137">
        <z:itemType>attachment</z:itemType>
        <dc:title>Trinh and Le - 2018 - A Simple Method for Commonsense Reasoning.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://linkinghub.elsevier.com/retrieve/pii/S0148296316304957">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:01482963"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Singh</foaf:surname>
                        <foaf:givenname>Jyoti Prakash</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Irani</foaf:surname>
                        <foaf:givenname>Seda</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rana</foaf:surname>
                        <foaf:givenname>Nripendra P.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dwivedi</foaf:surname>
                        <foaf:givenname>Yogesh K.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Saumya</foaf:surname>
                        <foaf:givenname>Sunil</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kumar Roy</foaf:surname>
                        <foaf:givenname>Pradeep</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_139"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://linkinghub.elsevier.com/retrieve/pii/S0148296316304957</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>346-355</bib:pages>
        <dc:date>01/2017</dc:date>
        <dcterms:dateSubmitted>2018-09-23 21:32:49</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online shopping is increasingly becoming people's ﬁrst choice when shopping, as it is very convenient to choose products based on their reviews. Even for moderately popular products, there are thousands of reviews constantly being posted on e-commerce sites. Such a large volume of data constantly being generated can be considered as a big data challenge for both online businesses and consumers. That makes it difﬁcult for buyers to go through all the reviews to make purchase decisions. In this research, we have developed models based on machine learning that can predict the helpfulness of the consumer reviews using several textual features such as polarity, subjectivity, entropy, and reading ease. The model will automatically assign helpfulness values to an initial review as soon as it is posted on the website so that the review gets a fair chance of being viewed by other buyers. The results of this study will help buyers to write better reviews and thereby assist other buyers in making their purchase decisions, as well as help businesses to improve their websites.</dcterms:abstract>
        <dc:title>Predicting the “helpfulness” of online consumer reviews</dc:title>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:01482963">
        <prism:volume>70</prism:volume>
        <dc:title>Journal of Business Research</dc:title>
        <dc:identifier>ISSN 01482963</dc:identifier>
        <dc:identifier>DOI 10.1016/j.jbusres.2016.08.008</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_139">
        <z:itemType>attachment</z:itemType>
        <dc:title>Singh et al. - 2017 - Predicting the “helpfulness” of online consumer re.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-4675-7">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-4675-7</dc:identifier>
                <dc:identifier>DOI 10.1145/3018661.3018665</dc:identifier>
                <dc:title>Proceedings of the Tenth ACM International Conference on Web Search and Data Mining - WSDM '17</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cambridge, United Kingdom</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zheng</foaf:surname>
                        <foaf:givenname>Lei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Noroozi</foaf:surname>
                        <foaf:givenname>Vahid</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yu</foaf:surname>
                        <foaf:givenname>Philip S.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_141"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?doid=3018661.3018665</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>425-434</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-09-23 21:34:03</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the Tenth ACM International Conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>A large amount of information exists in reviews written by users. This source of information has been ignored by most of the current recommender systems while it can potentially alleviate the sparsity problem and improve the quality of recommendations. In this paper, we present a deep model to learn item properties and user behaviors jointly from review text. The proposed model, named Deep Cooperative Neural Networks (DeepCoNN), consists of two parallel neural networks coupled in the last layers. One of the networks focuses on learning user behaviors exploiting reviews written by the user, and the other one learns item properties from the reviews written for the item. A shared layer is introduced on the top to couple these two networks together. The shared layer enables latent factors learned for users and items to interact with each other in a manner similar to factorization machine techniques. Experimental results demonstrate that DeepCoNN signiﬁcantly outperforms all baseline recommender systems on a variety of datasets.</dcterms:abstract>
        <dc:title>Joint Deep Modeling of Users and Items Using Reviews for Recommendation</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_141">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zheng et al. - 2017 - Joint Deep Modeling of Users and Items Using Revie.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-4144-8">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-4144-8</dc:identifier>
                <dc:identifier>DOI 10.1145/2872518.2890096</dc:identifier>
                <dc:title>Proceedings of the 25th International Conference Companion on World Wide Web - WWW '16 Companion</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                        <vcard:locality>Montr&amp;#233;al, Qu&amp;#233;bec, Canada</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rizos</foaf:surname>
                        <foaf:givenname>Georgios</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Papadopoulos</foaf:surname>
                        <foaf:givenname>Symeon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kompatsiaris</foaf:surname>
                        <foaf:givenname>Yiannis</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_144"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://dl.acm.org/citation.cfm?doid=2872518.2890096</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>737-742</bib:pages>
        <dc:date>2016</dc:date>
        <dcterms:dateSubmitted>2018-09-29 09:39:15</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the 25th International Conference Companion</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>The paper presents a framework for the prediction of several news story popularity indicators, such as comment count, number of users, vote score and a measure of controversiality. The framework employs a feature engineering approach, focusing on features from two sources of social interactions inherent in online discussions: the comment tree and the user graph. We show that the proposed graph-based features capture the complexities of both these social interaction graphs and lead to improvements on the prediction of all popularity indicators in three online news post datasets and to signiﬁcant improvement on the task of identifying controversial stories. Speciﬁcally, we noted a 5% relative improvement in mean square error for controversiality prediction on a news-focused Reddit dataset compared to a method employing only rudimentary comment tree features that were used by past studies.</dcterms:abstract>
        <dc:title>Predicting News Popularity by Mining Online Discussions</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_144">
        <z:itemType>attachment</z:itemType>
        <dc:title>Rizos et al. - 2016 - Predicting News Popularity by Mining Online Discus.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1808.08949">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1808.08949 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Peters</foaf:surname>
                        <foaf:givenname>Matthew E.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Neumann</foaf:surname>
                        <foaf:givenname>Mark</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zettlemoyer</foaf:surname>
                        <foaf:givenname>Luke</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yih</foaf:surname>
                        <foaf:givenname>Wen-tau</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_149"/>
        <link:link rdf:resource="#item_147"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1808.08949</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-08-27</dc:date>
        <dc:description>arXiv: 1808.08949</dc:description>
        <dcterms:dateSubmitted>2018-10-03 17:09:08</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Contextual word representations derived from pre-trained bidirectional language models (biLMs) have recently been shown to provide signiﬁcant improvements to the state of the art for a wide range of NLP tasks. However, many questions remain as to how and why these models are so effective. In this paper, we present a detailed empirical study of how the choice of neural architecture (e.g. LSTM, CNN, or self attention) inﬂuences both end task accuracy and qualitative properties of the representations that are learned. We show there is a tradeoff between speed and accuracy, but all architectures learn high quality contextual representations that outperform word embeddings for four challenging NLP tasks. Additionally, all architectures learn representations that vary with network depth, from exclusively morphological based at the word embedding layer through local syntax based in the lower contextual layers to longer range semantics such coreference at the upper layers. Together, these results suggest that unsupervised biLMs, independent of architecture, are learning much more about the structure of language than previously appreciated.</dcterms:abstract>
        <dc:title>Dissecting Contextual Word Embeddings: Architecture and Representation</dc:title>
        <z:shortTitle>Dissecting Contextual Word Embeddings</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_149">
       <rdf:value>&lt;p&gt;Comment: EMNLP 2018&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_147">
        <z:itemType>attachment</z:itemType>
        <dc:title>Peters et al. - 2018 - Dissecting Contextual Word Embeddings Architectur.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1708.00107">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1708.00107 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>McCann</foaf:surname>
                        <foaf:givenname>Bryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bradbury</foaf:surname>
                        <foaf:givenname>James</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Xiong</foaf:surname>
                        <foaf:givenname>Caiming</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Socher</foaf:surname>
                        <foaf:givenname>Richard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_150"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1708.00107</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-07-31</dc:date>
        <dc:description>arXiv: 1708.00107</dc:description>
        <dcterms:dateSubmitted>2018-10-03 20:18:42</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Computer vision has beneﬁted from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classiﬁcation (TREC), entailment (SNLI), and question answering (SQuAD). For ﬁne-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art.</dcterms:abstract>
        <dc:title>Learned in Translation: Contextualized Word Vectors</dc:title>
        <z:shortTitle>Learned in Translation</z:shortTitle>
    </bib:Article>
    <z:Attachment rdf:about="#item_150">
        <z:itemType>attachment</z:itemType>
        <dc:title>McCann et al. - 2017 - Learned in Translation Contextualized Word Vector.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1710.07395">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1710.07395 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gao</foaf:surname>
                        <foaf:givenname>Lei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Huang</foaf:surname>
                        <foaf:givenname>Ruihong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_154"/>
        <dcterms:isReferencedBy rdf:resource="#item_155"/>
        <link:link rdf:resource="#item_152"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1710.07395</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-10-19</dc:date>
        <dc:description>arXiv: 1710.07395</dc:description>
        <dcterms:dateSubmitted>2018-10-03 23:34:11</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>In the wake of a polarizing election, the cyber world is laden with hate speech. Context accompanying a hate speech text is useful for identifying hate speech, which however has been largely overlooked in existing datasets and hate speech detection models. In this paper, we provide an annotated corpus of hate speech with context information well kept. Then we propose two types of hate speech detection models that incorporate context information, a logistic regression model with context features and a neural network model with learning components for context. Our evaluation shows that both models outperform a strong baseline by around 3% to 4% in F1 score and combining these two models further improve the performance by another 7% in F1 score.</dcterms:abstract>
        <dc:title>Detecting Online Hate Speech Using Context Aware Models</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_154">
       <rdf:value>&lt;p&gt;Comment: Published in RANLP 2017&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Memo rdf:about="#item_155">
        <rdf:value>&lt;p&gt;They created their own dataset of annotated tweets so it's hard to compare. They used three LSTMs in parallel. Not really influencial but should be mentioned.&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_152">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gao and Huang - 2017 - Detecting Online Hate Speech Using Context Aware M.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_158">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>de Pelle</foaf:surname>
                        <foaf:givenname>Rogers Prates</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Moreira</foaf:surname>
                        <foaf:givenname>Viviane P</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_157"/>
        <bib:pages>10</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Brazilian Web users are among the most active in social networks and very keen on interacting with others. Offensive comments, known as hate speech, have been plaguing online media and originating a number of lawsuits against companies which publish Web content. Given the massive number of user generated text published on a daily basis, manually ﬁltering offensive comments becomes infeasible. The identiﬁcation of offensive comments can be treated as a supervised classiﬁcation task. In order to obtain a model to classify comments, an annotated dataset containing positive and negative examples is necessary. The lack of such a dataset in Portuguese, limits the development of detection approaches for this language. In this paper, we describe how we created annotated datasets of offensive comments for Portuguese by collecting news comments on the Brazilian Web. In addition, we provide classiﬁcation results achieved by standard classiﬁcation algorithms on these datasets which can serve as baseline for future work on this topic.</dcterms:abstract>
        <dc:title>Offensive Comments in the Brazilian Web: a dataset and baseline results</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_157">
        <z:itemType>attachment</z:itemType>
        <dc:title>de Pelle and Moreira - Offensive Comments in the Brazilian Web a dataset.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1705.09993">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1705.09993 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pavlopoulos</foaf:surname>
                        <foaf:givenname>John</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Malakasiotis</foaf:surname>
                        <foaf:givenname>Prodromos</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Androutsopoulos</foaf:surname>
                        <foaf:givenname>Ion</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_159"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1705.09993</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-05-28</dc:date>
        <dc:description>arXiv: 1705.09993</dc:description>
        <dcterms:dateSubmitted>2018-10-04 10:05:14</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Experimenting with a new dataset of 1.6M user comments from a Greek news portal and existing datasets of English Wikipedia comments, we show that an RNN outperforms the previous state of the art in moderation. A deep, classiﬁcation-speciﬁc attention mechanism improves further the overall performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation.</dcterms:abstract>
        <dc:title>Deep Learning for User Comment Moderation</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_159">
        <z:itemType>attachment</z:itemType>
        <dc:title>Pavlopoulos et al. - 2017 - Deep Learning for User Comment Moderation.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_163">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Goldberg</foaf:surname>
                        <foaf:givenname>Yoav</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_162"/>
        <bib:pages>309</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Neural Network Methods for Natural Language Processing</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_162">
        <z:itemType>attachment</z:itemType>
        <dc:title>Neural Network Methods for Natural Language Processing</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:978-0-07-042807-2">
        <z:itemType>book</z:itemType>
        <dcterms:isPartOf>
            <bib:Series>
               <dc:title>McGraw-Hill series in computer science</dc:title>
            </bib:Series>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New York</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>McGraw-Hill</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mitchell</foaf:surname>
                        <foaf:givenname>Tom M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_164"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer algorithms</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Machine learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>ISBN 978-0-07-042807-2</dc:identifier>
        <dc:date>1997</dc:date>
        <dc:subject>
           <dcterms:LCC><rdf:value>Q325.5 .M58 1997</rdf:value></dcterms:LCC>
        </dc:subject>
        <z:libraryCatalog>Library of Congress ISBN</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Machine Learning</dc:title>
        <z:numPages>414</z:numPages>
    </bib:Book>
    <z:Attachment rdf:about="#item_164">
        <z:itemType>attachment</z:itemType>
        <dc:title>Mitchell - 1997 - Machine Learning.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/W17-1101">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/W17-1101</dc:identifier>
                <dc:title>Proceedings of the Fifth International Workshop on Natural Language           Processing for Social Media</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Valencia, Spain</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schmidt</foaf:surname>
                        <foaf:givenname>Anna</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wiegand</foaf:surname>
                        <foaf:givenname>Michael</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_167"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/W17-1101</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1-10</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2018-10-09 10:48:31</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the Fifth International Workshop on Natural Language           Processing for Social Media</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>This paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing. Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing. We also discuss limits of those approaches.</dcterms:abstract>
        <dc:title>A Survey on Hate Speech Detection using Natural Language Processing</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_167">
        <z:itemType>attachment</z:itemType>
        <dc:title>Schmidt and Wiegand - 2017 - A Survey on Hate Speech Detection using Natural La.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_174">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Filter</foaf:surname>
                        <foaf:givenname>Johannes</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hagmeister</foaf:surname>
                        <foaf:givenname>Cornelius</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kellermeier</foaf:surname>
                        <foaf:givenname>Thomas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_173"/>
        <bib:pages>4</bib:pages>
        <dc:date>2018</dc:date>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>As the amount of comments that is posted daily on online newspapers increases, it becomes more and more di cult to moderate these sections. While this is mostly done manually, the advances in technology allow for machine supported moderation. In this paper we analyze how to automatically distinguish between popular and unpopular news comments. Based on data from the Guardian, we introduce a preprocessing which allows us to segment data based on normalized user up-votes. We create di erent datasets using only a part of the most popular and least popular comments, while discarding part of the comments to increase the contrast. In our experiments we use several classi ers, where our best classi er achieves an accuracy of 72%.</dcterms:abstract>
        <dc:title>Predicting Popular News Comments</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_173">
        <z:itemType>attachment</z:itemType>
        <dc:title>Filter et al. - 2018 - Predicting Popular News Comments.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_175">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bornstein</foaf:surname>
                        <foaf:givenname>Marvin</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gierke</foaf:surname>
                        <foaf:givenname>Willi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Nack</foaf:surname>
                        <foaf:givenname>Tobias</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_171"/>
        <bib:pages>4</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We propose an approach to select the most suitable comments summarizing discussions of online news articles. Our approach focuses on finding different topic clusters within a single discussion, which we can then summarize by finding representative comments. This ensures that the final summary covers a wider variety of topics discussed. The topic clusters are created by using the density based clustering approach DBSCAN on embeddings generated for the text of every comment using a neural network based on bi-directional LSTMs. We train the network using a triplet loss, forcing the embeddings of comments from the same article closer together compared to comments from different articles. With this approach, we compare similarly to the commercial summarization tool SMMRY judging by a user study with 12 participants.</dcterms:abstract>
        <dc:title>Approaching the Summarization of Online News Article Discussions with Topic Clusters based on Deep Neural Networks</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_171">
        <z:itemType>attachment</z:itemType>
        <dc:title>Bornstein et al. - Approaching the Summarization of Online News Artic.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_176">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kastius</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Preuß</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schall</foaf:surname>
                        <foaf:givenname>Maximilian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_170"/>
        <bib:pages>4</bib:pages>
        <dc:date>2018</dc:date>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Discussion Summarization</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_170">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kastius et al. - 2018 - Discussion Summarization.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="#item_177">
        <z:itemType>document</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ambroselli</foaf:surname>
                        <foaf:givenname>Carl</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_172"/>
        <dc:title>Quality Management for Online News Comments</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_172">
        <z:itemType>attachment</z:itemType>
        <dc:title>Thesis - Carl Ambroselli - Submission.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1803.09820">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
               <dc:title>arXiv:1803.09820 [cs, stat]</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smith</foaf:surname>
                        <foaf:givenname>Leslie N.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_181"/>
        <link:link rdf:resource="#item_179"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Statistics - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Computer Vision and Pattern Recognition</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Neural and Evolutionary Computing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1803.09820</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-03-26</dc:date>
        <dc:description>arXiv: 1803.09820</dc:description>
        <dcterms:dateSubmitted>2018-10-23 20:30:04</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Although deep learning has produced dazzling successes for applications of image, speech, and video processing in the past few years, most trainings are with suboptimal hyper-parameters, requiring unnecessarily long training times. Setting the hyper-parameters remains a black art that requires years of experience to acquire. This report proposes several efﬁcient ways to set the hyper-parameters that signiﬁcantly reduce training time and improves performance. Speciﬁcally, this report shows how to examine the training validation/test loss function for subtle clues of underﬁtting and overﬁtting and suggests guidelines for moving toward the optimal balance point. Then it discusses how to increase/decrease the learning rate/momentum to speed up training. Our experiments show that it is crucial to balance every manner of regularization for each dataset and architecture. Weight decay is used as a sample regularizer to show how its optimal value is tightly coupled with the learning rates and momentum. Files to help replicate the results reported here are available at https://github.com/lnsmith54/hyperParam1.</dcterms:abstract>
        <dc:title>A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay</dc:title>
        <z:shortTitle>A disciplined approach to neural network hyper-parameters</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_181">
        <rdf:value>Comment: Files to help replicate the results reported here are available on Github</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_179">
        <z:itemType>attachment</z:itemType>
        <dc:title>Smith - 2018 - A disciplined approach to neural network hyper-par.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1810.04805">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1810.04805 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Devlin</foaf:surname>
                        <foaf:givenname>Jacob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chang</foaf:surname>
                        <foaf:givenname>Ming-Wei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenname>Kenton</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Toutanova</foaf:surname>
                        <foaf:givenname>Kristina</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_184"/>
        <link:link rdf:resource="#item_182"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1810.04805</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-10-10</dc:date>
        <dc:description>arXiv: 1810.04805</dc:description>
        <dcterms:dateSubmitted>2018-10-25 11:18:25</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be ﬁne-tuned with just one additional output layer to create state-of-theart models for a wide range of tasks, such as question answering and language inference, without substantial task-speciﬁc architecture modiﬁcations.</dcterms:abstract>
        <dc:title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</dc:title>
        <z:shortTitle>BERT</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_184">
       <rdf:value>Comment: 13 pages</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_182">
        <z:itemType>attachment</z:itemType>
        <dc:title>Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transform.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1810.01114">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:title>arXiv:1810.01114 [cs]</dc:title>
                <dc:identifier>DOI 10.1145/3274336</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Häring</foaf:surname>
                        <foaf:givenname>Marlo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Loosen</foaf:surname>
                        <foaf:givenname>Wiebke</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Maalej</foaf:surname>
                        <foaf:givenname>Walid</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_187"/>
        <link:link rdf:resource="#item_185"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computers and Society</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1810.01114</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-10-02</dc:date>
        <dc:description>arXiv: 1810.01114</dc:description>
        <dcterms:dateSubmitted>2018-10-25 11:19:40</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>User comments have become an essential part of online journalism. However, newsrooms are often overwhelmed by the vast number of diverse comments, for which a manual analysis is barely feasible. Identifying meta-comments that address or mention newsrooms, individual journalists, or moderators and that may call for reactions is particularly critical. In this paper, we present an automated approach to identify and classify meta-comments. We compare comment classification based on manually extracted features with an end-to-end learning approach. We develop, optimize, and evaluate multiple classifiers on a comment dataset of the large German online newsroom SPIEGEL Online and the 'One Million Posts' corpus of DER STANDARD, an Austrian newspaper. Both optimized classification approaches achieved encouraging $F_{0.5}$ values between 76% and 91%. We report on the most significant classification features with the results of a qualitative analysis and discuss how our work contributes to making participation in online journalism more constructive.</dcterms:abstract>
        <dc:title>Who is Addressed in this Comment? Automatically Classifying Meta-Comments in News Comments</dc:title>
        <z:shortTitle>Who is Addressed in this Comment?</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_187">
        <rdf:value>Comment: Accepted for publication to the 21st ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW18)</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_185">
        <z:itemType>attachment</z:itemType>
        <dc:title>Häring et al. - 2018 - Who is Addressed in this Comment Automatically Cl.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Memo rdf:about="#item_193">
        <z:itemType>note</z:itemType>
        <rdf:value>&lt;p&gt;It is about traditional classification NLP meassurements&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.tandfonline.com/doi/full/10.1080/1369118X.2017.1324505">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1369-118X,%201468-4462"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ziegele</foaf:surname>
                        <foaf:givenname>Marc</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weber</foaf:surname>
                        <foaf:givenname>Mathias</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Quiring</foaf:surname>
                        <foaf:givenname>Oliver</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Breiner</foaf:surname>
                        <foaf:givenname>Timo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_199"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.tandfonline.com/doi/full/10.1080/1369118X.2017.1324505</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1419-1435</bib:pages>
        <dc:date>2018-10-03</dc:date>
        <dcterms:dateSubmitted>2018-11-22 20:55:12</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>The dynamics of online news discussions: effects of news articles and reader comments on users’ involvement, willingness to participate, and the civility of their contributions</dc:title>
        <z:shortTitle>The dynamics of online news discussions</z:shortTitle>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1369-118X,%201468-4462">
        <prism:volume>21</prism:volume>
        <prism:number>10</prism:number>
        <dc:title>Information, Communication &amp; Society</dc:title>
        <dc:identifier>ISSN 1369-118X, 1468-4462</dc:identifier>
        <dc:identifier>DOI 10.1080/1369118X.2017.1324505</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_199">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ziegele et al. - 2018 - The dynamics of online news discussions effects o.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1209977">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1461-670X,%201469-9699"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ksiazek</foaf:surname>
                        <foaf:givenname>Thomas B.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_200"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1209977</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>650-673</bib:pages>
        <dc:date>2018-04-04</dc:date>
        <dcterms:dateSubmitted>2018-11-22 20:55:14</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Commenting on the News: Explaining the degree and quality of user comments on news websites</dc:title>
        <z:shortTitle>Commenting on the News</z:shortTitle>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1461-670X,%201469-9699">
        <prism:volume>19</prism:volume>
        <prism:number>5</prism:number>
        <dc:title>Journalism Studies</dc:title>
        <dc:identifier>ISSN 1461-670X, 1469-9699</dc:identifier>
        <dc:identifier>DOI 10.1080/1461670X.2016.1209977</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_200">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ksiazek - 2018 - Commenting on the News Explaining the degree and .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://econtent.hogrefe.com/doi/10.1027/1864-1105/a000217">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1864-1105,%202151-2388"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weber</foaf:surname>
                        <foaf:givenname>Patrick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Prochazka</foaf:surname>
                        <foaf:givenname>Fabian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schweiger</foaf:surname>
                        <foaf:givenname>Wolfgang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_203"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://econtent.hogrefe.com/doi/10.1027/1864-1105/a000217</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1-11</bib:pages>
        <dc:date>2017-04-28</dc:date>
        <dcterms:dateSubmitted>2018-11-22 20:55:17</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>User comments on news websites are frequently uncivil and are not supported by reasoned argumentation. These characteristics can have negative effects on the perceived quality of the commented-on journalistic content, yet to date, it remains unclear how such effects occur. We propose three mechanisms that assume that the effect of user comments depends on how deliberately and elaborately the quality of the commented-on news item is judged. We conducted an experiment (N = 633) in which we varied the level of civility and reasoning in the comments accompanying a news article and the brand of the news website on which it was presented. The results showed that a lack of reasoning in the comments decreased the perceived quality of the news item irrespective of brand awareness, but only with high elaboration during judgment. Incivility in the comments decreased the perceived quality of the journalistic content, but only with low elaboration, and only with an unknown news brand. We discuss different psychological mechanisms that can explain this pattern of effects.</dcterms:abstract>
        <dc:title>Why User Comments Affect the Perceived Quality of Journalistic Content: The Role of Judgment Processes</dc:title>
        <z:shortTitle>Why User Comments Affect the Perceived Quality of Journalistic Content</z:shortTitle>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1864-1105,%202151-2388">
        <dc:title>Journal of Media Psychology</dc:title>
        <dc:identifier>ISSN 1864-1105, 2151-2388</dc:identifier>
        <dc:identifier>DOI 10.1027/1864-1105/a000217</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_203">
        <z:itemType>attachment</z:itemType>
        <dc:title>Weber et al. - 2017 - Why User Comments Affect the Perceived Quality of .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1161497">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <prism:volume>19</prism:volume>
                <prism:number>1</prism:number>
                <dc:title>Journalism Studies</dc:title>
                <dc:identifier>ISSN 1461-670X, 1469-9699</dc:identifier>
                <dc:identifier>DOI 10.1080/1461670X.2016.1161497</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Prochazka</foaf:surname>
                        <foaf:givenname>Fabian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weber</foaf:surname>
                        <foaf:givenname>Patrick</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Schweiger</foaf:surname>
                        <foaf:givenname>Wolfgang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_205"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1161497</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>62-78</bib:pages>
        <dc:date>2018-01-02</dc:date>
        <dcterms:dateSubmitted>2018-11-22 20:55:21</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Effects of Civility and Reasoning in User Comments on Perceived Journalistic Quality</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_205">
        <z:itemType>attachment</z:itemType>
        <dc:title>Prochazka et al. - 2018 - Effects of Civility and Reasoning in User Comments.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/D17-1231">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/D17-1231</dc:identifier>
                <dc:title>Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Copenhagen, Denmark</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenname>Yang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Han</foaf:surname>
                        <foaf:givenname>Kun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tan</foaf:surname>
                        <foaf:givenname>Zhao</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lei</foaf:surname>
                        <foaf:givenname>Yun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_208"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/D17-1231</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>2170-2178</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2019-01-03 18:20:15</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Previous work on dialog act (DA) classiﬁcation has investigated different methods, such as hidden Markov models, maximum entropy, conditional random ﬁelds, graphical models, and support vector machines. A few recent studies explored using deep learning neural networks for DA classiﬁcation, however, it is not clear yet what is the best method for using dialog context or DA sequential information, and how much gain it brings. This paper proposes several ways of using context information for DA classiﬁcation, all in the deep learning framework. The baseline system classiﬁes each utterance using the convolutional neural networks (CNN). Our proposed methods include using hierarchical models (recurrent neural networks (RNN) or CNN) for DA sequence tagging where the bottom layer takes the sentence CNN representation as input, concatenating predictions from the previous utterances with the CNN vector for classiﬁcation, and performing sequence decoding based on the predictions from the sentence CNN model. We conduct thorough experiments and comparisons on the Switchboard corpus, demonstrate that incorporating context information signiﬁcantly improves DA classiﬁcation, and show that we achieve new state-of-the-art performance for this task.</dcterms:abstract>
        <dc:title>Using Context Information for Dialog Act Classification in DNN Framework</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_208">
        <z:itemType>attachment</z:itemType>
        <dc:title>Liu et al. - 2017 - Using Context Information for Dialog Act Classific.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_212">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weninger</foaf:surname>
                        <foaf:givenname>Tim</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhu</foaf:surname>
                        <foaf:givenname>Xihao Avi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Han</foaf:surname>
                        <foaf:givenname>Jiawei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_211"/>
        <bib:pages>5</bib:pages>
        <dc:date>2013</dc:date>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>An Exploration of Discussion Threads in Social News Sites: A Case Study of the Reddit Community</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_211">
        <z:itemType>attachment</z:itemType>
        <dc:title>Weninger et al. - 2013 - An Exploration of Discussion Threads in Social New.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_214">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Backstrom</foaf:surname>
                        <foaf:givenname>Lars</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kleinberg</foaf:surname>
                        <foaf:givenname>Jon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenname>Lillian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Danescu-Niculescu-Mizil</foaf:surname>
                        <foaf:givenname>Cristian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_213"/>
        <bib:pages>10</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Discussion threads form a central part of the experience on many Web sites, including social networking sites such as Facebook and Google Plus and knowledge creation sites such as Wikipedia. To help users manage the challenge of allocating their attention among the discussions that are relevant to them, there has been a growing need for the algorithmic curation of on-line conversations — the development of automated methods to select a subset of discussions to present to a user.</dcterms:abstract>
        <dc:title>Characterizing and curating conversation threads: expansion, focus, volume, re-entry</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_213">
        <z:itemType>attachment</z:itemType>
        <dc:title>Backstrom et al. - Characterizing and curating conversation threads .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_217">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Aragon</foaf:surname>
                        <foaf:givenname>Pablo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gomez</foaf:surname>
                        <foaf:givenname>Vicenc</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kaltenbrunner</foaf:surname>
                        <foaf:givenname>Andreas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_216"/>
        <bib:pages>10</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online discussion is essential for the communication and collaboration of online communities. The reciprocal exchange of messages between users that characterizes online discussion can be represented in many diﬀerent ways. While some platforms display messages chronologically using a simple linear interface, others use a hierarchical (threaded) interface to represent more explicitly the structure of the discussion. Although the type of representation has been shown to aﬀect communication, to the best of our knowledge, the impact of using either one or the other has not yet been investigated in a large and mature online community.</dcterms:abstract>
        <dc:title>To Thread or Not to Thread: The Impact of Conversation Threading on Online Discussion</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_216">
        <z:itemType>attachment</z:itemType>
        <dc:title>Aragon et al. - To Thread or Not to Thread The Impact of Conversa.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_219">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zayats</foaf:surname>
                        <foaf:givenname>Victoria</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ostendorf</foaf:surname>
                        <foaf:givenname>Mari</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_239"/>
        <link:link rdf:resource="#item_218"/>
        <dc:subject>important</dc:subject>
        <bib:pages>12</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>This paper presents a novel approach for modeling threaded discussions on social media using a graph-structured bidirectional LSTM (long-short term memory) which represents both hierarchical and temporal conversation structure. In experiments with a task of predicting popularity of comments in Reddit discussions, the proposed model outperforms a node-independent architecture for different sets of input features. Analyses show a beneﬁt to the model over the full course of the discussion, improving detection in both early and late stages. Further, the use of language cues with the bidirectional tree state updates helps with identifying controversial comments.</dcterms:abstract>
        <dc:title>Conversation Modeling on Reddit Using a Graph-Structured LSTM</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_239">
        <rdf:value>&lt;p&gt;Adapted LSTM to add another hierachiarical connection &lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_218">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zayats and Ostendorf - Conversation Modeling on Reddit Using a Graph-Stru.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1606.03667">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1606.03667 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>He</foaf:surname>
                        <foaf:givenname>Ji</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ostendorf</foaf:surname>
                        <foaf:givenname>Mari</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>He</foaf:surname>
                        <foaf:givenname>Xiaodong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Jianshu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gao</foaf:surname>
                        <foaf:givenname>Jianfeng</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenname>Lihong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Deng</foaf:surname>
                        <foaf:givenname>Li</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_225"/>
        <dcterms:isReferencedBy rdf:resource="#item_265"/>
        <link:link rdf:resource="#item_222"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Machine Learning</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1606.03667</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2016-06-12</dc:date>
        <dc:description>arXiv: 1606.03667</dc:description>
        <dcterms:dateSubmitted>2019-01-14 14:49:01</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial, natural language action space. A speciﬁed number of discussion threads predicted to be popular are recommended, chosen from a ﬁxed window of recent comments to track. Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub-actions. The proposed model, which represents dependence between sub-actions through a bi-directional LSTM, gives the best performance across different experimental conﬁgurations and domains, and it also generalizes well with varying numbers of recommendation requests.</dcterms:abstract>
        <dc:title>Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_225">
        <rdf:value>&lt;p&gt;Comment: To be published in EMNLP 2016, 11 pages&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Memo rdf:about="#item_265">
        <rdf:value>&lt;div class=&quot;page&quot; title=&quot;Page 6&quot;&gt;
&lt;div class=&quot;section&quot;&gt;
&lt;div class=&quot;layoutArea&quot;&gt;
&lt;div class=&quot;column&quot;&gt;
&lt;p&gt;&lt;span style=&quot;font-size: 11.000000pt; font-family: 'NimbusRomNo9L';&quot;&gt;In our experiments, in order to have long enough discussion threads, we filter out discussion trees with fewer than 100 comments. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Fixed Window set of N=20&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_222">
        <z:itemType>attachment</z:itemType>
        <dc:title>He et al. - 2016 - Deep Reinforcement Learning with a Combinatorial A.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1608.04808">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1608.04808 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fang</foaf:surname>
                        <foaf:givenname>Hao</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cheng</foaf:surname>
                        <foaf:givenname>Hao</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ostendorf</foaf:surname>
                        <foaf:givenname>Mari</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_227"/>
        <link:link rdf:resource="#item_223"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Social and Information Networks</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1608.04808</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2016-08-16</dc:date>
        <dc:description>arXiv: 1608.04808</dc:description>
        <dcterms:dateSubmitted>2019-01-14 14:49:05</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Many social media platforms offer a mechanism for readers to react to comments, both positively and negatively, which in aggregate can be thought of as community endorsement. This paper addresses the problem of predicting community endorsement in online discussions, leveraging both the participant response structure and the text of the comment. The different types of features are integrated in a neural network that uses a novel architecture to learn latent modes of discussion structure that perform as well as deep neural networks but are more interpretable. In addition, the latent modes can be used to weight text features thereby improving prediction accuracy.</dcterms:abstract>
        <dc:title>Learning Latent Local Conversation Modes for Predicting Community Endorsement in Online Discussions</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_227">
       <rdf:value>Comment: 10 pages, 7 figures</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_223">
        <z:itemType>attachment</z:itemType>
        <dc:title>Fang et al. - 2016 - Learning Latent Local Conversation Modes for Predi.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_229">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jaech</foaf:surname>
                        <foaf:givenname>Aaron</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ostendorf</foaf:surname>
                        <foaf:givenname>Mari</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_228"/>
        <bib:pages>14</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>A context-aware language model uses location, user and/or domain metadata (context) to adapt its predictions. In neural language models, context information is typically represented as an embedding and it is given to the RNN as an additional input, which has been shown to be useful in many applications. We introduce a more powerful mechanism for using context to adapt an RNN by letting the context vector control a low-rank transformation of the recurrent layer weight matrix. Experiments show that allowing a greater fraction of the model parameters to be adjusted has beneﬁts in terms of perplexity and classiﬁcation for several different types of context.</dcterms:abstract>
        <dc:title>Low-Rank RNN Adaptation for Context-Aware Language Modeling</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_228">
        <z:itemType>attachment</z:itemType>
        <dc:title>Jaech and Ostendorf - Low-Rank RNN Adaptation for Context-Aware Language.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1704.06380">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1704.06380 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jaech</foaf:surname>
                        <foaf:givenname>Aaron</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ostendorf</foaf:surname>
                        <foaf:givenname>Mari</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_230"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1704.06380</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-04-20</dc:date>
        <dc:description>arXiv: 1704.06380</dc:description>
        <dcterms:dateSubmitted>2019-01-14 14:52:52</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Increased adaptability of RNN language models leads to improved predictions that beneﬁt many applications. However, current methods do not take full advantage of the RNN structure. We show that the most widely-used approach to adaptation (concatenating the context with the word embedding at the input to the recurrent layer) is outperformed by a model that has some low-cost improvements: adaptation of both the hidden and output layers. and a feature hashing bias term to capture context idiosyncrasies. Experiments on language modeling and classiﬁcation tasks using three different corpora demonstrate the advantages of the proposed techniques.</dcterms:abstract>
        <dc:title>Improving Context Aware Language Models</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_230">
        <z:itemType>attachment</z:itemType>
        <dc:title>Jaech and Ostendorf - 2017 - Improving Context Aware Language Models.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/N16-1149">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/N16-1149</dc:identifier>
                <dc:title>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>San Diego, California</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hoang</foaf:surname>
                        <foaf:givenname>Cong Duy Vu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cohn</foaf:surname>
                        <foaf:givenname>Trevor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Haffari</foaf:surname>
                        <foaf:givenname>Gholamreza</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_232"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/N16-1149</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1250-1255</bib:pages>
        <dc:date>2016</dc:date>
        <dcterms:dateSubmitted>2019-01-14 15:00:46</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Recurrent neural network language models (RNNLM) have recently demonstrated vast potential in modelling long-term dependencies for NLP problems, ranging from speech recognition to machine translation. In this work, we propose methods for conditioning RNNLMs on external side information, e.g., metadata such as keywords, description, document title or topic headline. Our experiments show consistent improvements of RNNLMs using side information over the baselines for two different datasets and genres in two languages. Interestingly, we found that side information in a foreign language can be highly beneﬁcial in modelling texts in another language, serving as a form of cross-lingual language modelling.</dcterms:abstract>
        <dc:title>Incorporating Side Information into Recurrent Neural Network Language Models</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_232">
        <z:itemType>attachment</z:itemType>
        <dc:title>Hoang et al. - 2016 - Incorporating Side Information into Recurrent Neur.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_235">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miura</foaf:surname>
                        <foaf:givenname>Yasuhide</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kano</foaf:surname>
                        <foaf:givenname>Ryuji</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taniguchi</foaf:surname>
                        <foaf:givenname>Motoki</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Taniguchi</foaf:surname>
                        <foaf:givenname>Tomoki</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Misawa</foaf:surname>
                        <foaf:givenname>Shotaro</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ohkuma</foaf:surname>
                        <foaf:givenname>Tomoko</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_234"/>
        <bib:pages>13</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>We proposed a model that integrates discussion structures with neural networks to classify discourse acts. Several attempts have been made in earlier works to analyze texts that are used in various discussions. The importance of discussion structures has been explored in those works but their methods required a sophisticated design to combine structural features with a classiﬁer. Our model introduces tree learning approaches and a graph learning approach to directly capture discussion structures without structural features. In an evaluation to classify discussion discourse acts in Reddit, the model achieved improvements of 1.5% in accuracy and 2.2 in F1 score compared to the previous best model. We further analyzed the model using an attention mechanism to inspect interactions among different learning approaches.</dcterms:abstract>
        <dc:title>Integrating Tree Structures and Graph Structures with Neural Networks to Classify Discussion Discourse Acts</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_234">
        <z:itemType>attachment</z:itemType>
        <dc:title>Miura et al. - Integrating Tree Structures and Graph Structures w.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1809.05679">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1809.05679 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yao</foaf:surname>
                        <foaf:givenname>Liang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mao</foaf:surname>
                        <foaf:givenname>Chengsheng</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Luo</foaf:surname>
                        <foaf:givenname>Yuan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_238"/>
        <link:link rdf:resource="#item_236"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1809.05679</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-09-15</dc:date>
        <dc:description>arXiv: 1809.05679</dc:description>
        <dcterms:dateSubmitted>2019-01-14 15:15:16</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Text classiﬁcation is an important and classical problem in natural language processing. There have been a number of studies that applied convolutional neural networks (convolution on regular grid, e.g., sequence) to classiﬁcation. However, only a limited number of studies have explored the more ﬂexible graph convolutional neural networks (convolution on non-grid, e.g., arbitrary graph) for the task. In this work, we propose to use graph convolutional networks for text classiﬁcation. We build a single text graph for a corpus based on word co-occurrence and document word relations, then learn a Text Graph Convolutional Network (Text GCN) for the corpus. Our Text GCN is initialized with one-hot representation for word and document, it then jointly learns the embeddings for both words and documents, as supervised by the known class labels for documents. Our experimental results on multiple benchmark datasets demonstrate that a vanilla Text GCN without any external word embeddings or knowledge outperforms state-of-the-art methods for text classiﬁcation. On the other hand, Text GCN also learns predictive word and document embeddings. In addition, experimental results show that the improvement of Text GCN over state-of-the-art comparison methods become more prominent as we lower the percentage of training data, suggesting the robustness of Text GCN to less training data in text classiﬁcation.</dcterms:abstract>
        <dc:title>Graph Convolutional Networks for Text Classification</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_238">
        <rdf:value>&lt;p&gt;Comment: Accepted by 33rd AAAI Conference on Artificial Intelligence (AAAI 2019)&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_236">
        <z:itemType>attachment</z:itemType>
        <dc:title>Yao et al. - 2018 - Graph Convolutional Networks for Text Classificati.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/N18-1164">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/N18-1164</dc:identifier>
                <dc:title>Proceedings of the 2018 Conference of the North American Chapter of           the Association for Computational Linguistics: Human Language           Technologies, Volume 1 (Long Papers)</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>New Orleans, Louisiana</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jiang</foaf:surname>
                        <foaf:givenname>Jyun-Yu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Francine</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Yan-Ying</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Wei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_248"/>
        <link:link rdf:resource="#item_240"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/N18-1164</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1812-1822</bib:pages>
        <dc:date>2018</dc:date>
        <dcterms:dateSubmitted>2019-01-14 15:43:53</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 2018 Conference of the North American Chapter of           the Association for Computational Linguistics: Human Language           Technologies, Volume 1 (Long Papers)</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>An enormous amount of conversation occurs online every day, such as on chat platforms where multiple conversations may take place concurrently. Interleaved conversations lead to difﬁculties in not only following discussions but also retrieving relevant information from simultaneous messages. Conversation disentanglement aims to separate intermingled messages into detached conversations.</dcterms:abstract>
        <dc:title>Learning to Disentangle Interleaved Conversational Threads with a Siamese Hierarchical Network and Similarity Ranking</dc:title>
    </rdf:Description>
    <bib:Memo rdf:about="#item_248">
        <rdf:value>&lt;p&gt;put all comments in a thread into a bag and try to reconstruct the threads, siamese network&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_240">
        <z:itemType>attachment</z:itemType>
        <dc:title>Jiang et al. - 2018 - Learning to Disentangle Interleaved Conversational.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_243">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhang</foaf:surname>
                        <foaf:givenname>Amy X</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Culbertson</foaf:surname>
                        <foaf:givenname>Bryan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Paritosh</foaf:surname>
                        <foaf:givenname>Praveen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_242"/>
        <bib:pages>10</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>In this work, we present a novel method for classifying comments in online discussions into a set of coarse discourse acts towards the goal of better understanding discussions at scale. To facilitate this study, we devise a categorization of coarse discourse acts designed to encompass general online discussion and allow for easy annotation by crowd workers. We collect and release a corpus of over 9,000 threads comprising over 100,000 comments manually annotated via paid crowdsourcing with discourse acts and randomly sampled from the site Reddit. Using our corpus, we demonstrate how the analysis of discourse acts can characterize different types of discussions, including discourse sequences such as Q&amp;A pairs and chains of disagreement, as well as different communities. Finally, we conduct experiments to predict discourse acts using our corpus, ﬁnding that structured prediction models such as conditional random ﬁelds can achieve an F1 score of 75%. We also demonstrate how the broadening of discourse acts from simply question and answer to a richer set of categories can improve the recall performance of Q&amp;A extraction.</dcterms:abstract>
        <dc:title>Characterizing Online Discussion Using Coarse Discourse Sequences</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_242">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zhang et al. - Characterizing Online Discussion Using Coarse Disc.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_245">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <prism:volume>44</prism:volume>
                <prism:number>4</prism:number>
                <dc:title>Computational Linguistics</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ghosh</foaf:surname>
                        <foaf:givenname>Debanjan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fabbri</foaf:surname>
                        <foaf:givenname>Alexander R</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Muresan</foaf:surname>
                        <foaf:givenname>Smaranda</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_244"/>
        <bib:pages>38</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>Sarcasm Analysis Using Conversation Context</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_244">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ghosh et al. - Sarcasm Analysis Using Conversation Context.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/W17-5523">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/W17-5523</dc:identifier>
                <dc:title>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Saarbrücken, Germany</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ghosh</foaf:surname>
                        <foaf:givenname>Debanjan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Richard Fabbri</foaf:surname>
                        <foaf:givenname>Alexander</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Muresan</foaf:surname>
                        <foaf:givenname>Smaranda</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_246"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/W17-5523</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>186-196</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2019-01-16 16:12:17</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, speaker’s sarcastic intent is not always obvious without additional context. Focusing on social media discussions, we investigate two issues: (1) does modeling of conversation context help in sarcasm detection and (2) can we understand what part of conversation context triggered the sarcastic reply. To address the ﬁrst issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the sarcastic response.1 We show that the conditional LSTM network (Rockta¨schel et al., 2015) and LSTM networks with sentence level attention on context and response outperform the LSTM model that reads only the response. To address the second issue, we present a qualitative analysis of attention weights produced by the LSTM models with attention and discuss the results compared with human performance on the task.</dcterms:abstract>
        <dc:title>The Role of Conversation Context for Sarcasm Detection in Online Interactions</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_246">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ghosh et al. - 2017 - The Role of Conversation Context for Sarcasm Detec.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:BookSection rdf:about="urn:isbn:978-3-642-20160-8%20978-3-642-20161-5">
        <z:itemType>bookSection</z:itemType>
        <dcterms:isPartOf>
            <bib:Book>
                <prism:volume>6611</prism:volume>
                <dc:identifier>ISBN 978-3-642-20160-8 978-3-642-20161-5</dc:identifier>
                <dc:title>Advances in Information Retrieval</dc:title>
            </bib:Book>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Berlin, Heidelberg</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer Berlin Heidelberg</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:editors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Clough</foaf:surname>
                        <foaf:givenname>Paul</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Foley</foaf:surname>
                        <foaf:givenname>Colum</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gurrin</foaf:surname>
                        <foaf:givenname>Cathal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jones</foaf:surname>
                        <foaf:givenname>Gareth J. F.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kraaij</foaf:surname>
                        <foaf:givenname>Wessel</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenname>Hyowon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mudoch</foaf:surname>
                        <foaf:givenname>Vanessa</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:editors>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Duan</foaf:surname>
                        <foaf:givenname>Huizhong</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhai</foaf:surname>
                        <foaf:givenname>Chengxiang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_249"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://link.springer.com/10.1007/978-3-642-20161-5_35</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>350-361</bib:pages>
        <dc:date>2011</dc:date>
        <dc:description>DOI: 10.1007/978-3-642-20161-5_35</dc:description>
        <dcterms:dateSubmitted>2019-01-16 20:41:59</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Due to many unique characteristics of forum data, forum post retrieval is diﬀerent from traditional document retrieval and web search, raising interesting research questions about how to optimize the accuracy of forum post retrieval. In this paper, we study how to exploit the naturally available raw thread structures of forums to improve retrieval accuracy in the language modeling framework. Speciﬁcally, we propose and study two diﬀerent schemes for smoothing the language model of a forum post based on the thread containing the post. We explore several diﬀerent variants of the two schemes to exploit thread structures in diﬀerent ways. We also create a human annotated test data set for forum post retrieval and evaluate the proposed smoothing methods using this data set. The experiment results show that the proposed methods for leveraging forum threads to improve estimation of document language models are eﬀective, and they outperform the existing smoothing methods for the forum post retrieval task.</dcterms:abstract>
        <dc:title>Exploiting Thread Structures to Improve Smoothing of Language Models for Forum Post Retrieval</dc:title>
    </bib:BookSection>
    <z:Attachment rdf:about="#item_249">
        <z:itemType>attachment</z:itemType>
        <dc:title>Duan and Zhai - 2011 - Exploiting Thread Structures to Improve Smoothing .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-60558-512-3">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-60558-512-3</dc:identifier>
                <dc:identifier>DOI 10.1145/1645953.1646262</dc:identifier>
                <dc:title>Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Hong Kong, China</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Seo</foaf:surname>
                        <foaf:givenname>Jangwon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Croft</foaf:surname>
                        <foaf:givenname>W. Bruce</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Smith</foaf:surname>
                        <foaf:givenname>David A.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_251"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://portal.acm.org/citation.cfm?doid=1645953.1646262</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1907</bib:pages>
        <dc:date>2009</dc:date>
        <dcterms:dateSubmitted>2019-01-16 20:43:11</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>Proceeding of the 18th ACM conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Online communities are valuable information sources where knowledge is accumulated by interactions between people. Search services provided by online community sites such as forums are often, however, quite poor. To address this, we investigate retrieval techniques that exploit the hierarchical thread structures in community sites. Since these structures are sometimes not explicit or accurately annotated, we use structure discovery techniques. We then make use of thread structures in retrieval experiments. Our results show that using thread structures that have been accurately annotated can lead to signiﬁcant improvements in retrieval performance compared to strong baselines.</dcterms:abstract>
        <dc:title>Online community search using thread structure</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_251">
        <z:itemType>attachment</z:itemType>
        <dc:title>Seo et al. - 2009 - Online community search using thread structure.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="urn:isbn:978-1-4503-0757-4">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-1-4503-0757-4</dc:identifier>
                <dc:identifier>DOI 10.1145/2009916.2009976</dc:identifier>
                <dc:title>Proceedings of the 34th international ACM SIGIR conference on Research and development in Information - SIGIR '11</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Beijing, China</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>ACM Press</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Hongning</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenname>Chi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhai</foaf:surname>
                        <foaf:givenname>ChengXiang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Han</foaf:surname>
                        <foaf:givenname>Jiawei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_253"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://portal.acm.org/citation.cfm?doid=2009916.2009976</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>435</bib:pages>
        <dc:date>2011</dc:date>
        <dcterms:dateSubmitted>2019-01-16 20:45:47</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
               <dc:title>the 34th international ACM SIGIR conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Online forum discussions are emerging as valuable information repository, where knowledge is accumulated by the interaction among users, leading to multiple threads with structures. Such replying structure in each thread conveys important information about the discussion content. Unfortunately, not all the online forum sites would explicitly record such replying relationship, making it hard for both users and computers to digest the information buried in a discussion thread.</dcterms:abstract>
        <dc:title>Learning online discussion structures by conditional random fields</dc:title>
    </rdf:Description>
    <z:Attachment rdf:about="#item_253">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wang et al. - 2011 - Learning online discussion structures by condition.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_256">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Singh</foaf:surname>
                        <foaf:givenname>Amit</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_255"/>
        <bib:pages>10</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online forums are becoming a popular way of ﬁnding useful information on the web. Search over forums for existing discussion threads so far is limited to keyword-based search due to the minimal eﬀort required on part of the users. However, it is often not possible to capture all the relevant context in a complex query using a small number of keywords. Examplebased search that retrieves similar discussion threads given one exemplary thread is an alternate approach that can help the user provide richer context and vastly improve forum search results. In this paper, we address the problem of ﬁnding similar threads to a given thread. Towards this, we propose a novel methodology to estimate similarity between discussion threads. Our method exploits the thread structure to decompose threads in to set of weighted overlapping components. It then estimates pairwise thread similarities by quantifying how well the information in the threads are mutually contained within each other using lexical similarities between their underlying components. We compare our proposed methods on real datasets against state-of-the-art thread retrieval mechanisms wherein we illustrate that our techniques outperform others by large margins on popular retrieval evaluation measures such as NDCG, MAP, Precision@k and MRR. In particular, consistent improvements of up to 10% are observed on all evaluation measures.</dcterms:abstract>
        <dc:title>Retrieving similar discussion forum threads: a structure based approach</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_255">
        <z:itemType>attachment</z:itemType>
        <dc:title>Singh - Retrieving similar discussion forum threads a str.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_258">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zubiaga</foaf:surname>
                        <foaf:givenname>Arkaitz</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kochkina</foaf:surname>
                        <foaf:givenname>Elena</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liakata</foaf:surname>
                        <foaf:givenname>Maria</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Procter</foaf:surname>
                        <foaf:givenname>Rob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lukasik</foaf:surname>
                        <foaf:givenname>Michal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_257"/>
        <bib:pages>11</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Rumour stance classiﬁcation, the task that determines if each tweet in a collection discussing a rumour is supporting, denying, questioning or simply commenting on the rumour, has been attracting substantial interest. Here we introduce a novel approach that makes use of the sequence of transitions observed in tree-structured conversation threads in Twitter. The conversation threads are formed by harvesting users’ replies to one another, which results in a nested tree-like structure. Previous work addressing the stance classiﬁcation task has treated each tweet as a separate unit. Here we analyse tweets by virtue of their position in a sequence and test two sequential classiﬁers, Linear-Chain CRF and Tree CRF, each of which makes different assumptions about the conversational structure. We experiment with eight Twitter datasets, collected during breaking news, and show that exploiting the sequential structure of Twitter conversations achieves signiﬁcant improvements over the non-sequential methods. Our work is the ﬁrst to model Twitter conversations as a tree structure in this manner, introducing a novel way of tackling NLP tasks on Twitter conversations.</dcterms:abstract>
        <dc:title>Stance Classification in Rumours as a Sequential Task Exploiting the Tree Structure of Social Media Conversations</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_257">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zubiaga et al. - Stance Classification in Rumours as a Sequential T.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="http://aclweb.org/anthology/D15-1178">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/D15-1178</dc:identifier>
                <dc:title>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Lisbon, Portugal</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Louis</foaf:surname>
                        <foaf:givenname>Annie</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cohen</foaf:surname>
                        <foaf:givenname>Shay B.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_259"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/D15-1178</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1543-1553</bib:pages>
        <dc:date>2015</dc:date>
        <dcterms:dateSubmitted>2019-01-16 21:05:20</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>Online forum discussions proceed differently from face-to-face conversations and any single thread on an online forum contains posts on different subtopics. This work aims to characterize the content of a forum thread as a conversation tree of topics. We present models that jointly perform two tasks: segment a thread into subparts, and assign a topic to each part. Our core idea is a deﬁnition of topic structure using probabilistic grammars. By leveraging the ﬂexibility of two grammar formalisms, Context-Free Grammars and Linear Context-Free Rewriting Systems, our models create desirable structures for forum threads: our topic segmentation is hierarchical, links non-adjacent segments on the same topic, and jointly labels the topic during segmentation. We show that our models outperform a number of tree generation baselines.</dcterms:abstract>
        <dc:title>Conversation Trees: A Grammar Model for Topic Structure in Forums</dc:title>
        <z:shortTitle>Conversation Trees</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_259">
        <z:itemType>attachment</z:itemType>
        <dc:title>Louis and Cohen - 2015 - Conversation Trees A Grammar Model for Topic Stru.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://jisajournal.springeropen.com/articles/10.1186/s13174-017-0066-z">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1867-4828,%201869-0238"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Aragón</foaf:surname>
                        <foaf:givenname>Pablo</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gómez</foaf:surname>
                        <foaf:givenname>Vicenç</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>García</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kaltenbrunner</foaf:surname>
                        <foaf:givenname>Andreas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_261"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://jisajournal.springeropen.com/articles/10.1186/s13174-017-0066-z</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>12/2017</dc:date>
        <dcterms:dateSubmitted>2019-01-16 21:07:53</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online discussion in form of written comments is a core component of many social media platforms. It has attracted increasing attention from academia, mainly because theories from social sciences can be explored at an unprecedented scale. This interest has led to the development of statistical models which are able to characterize the dynamics of threaded online conversations. In this paper, we review research on statistical modeling of online discussions, in particular, we describe current generative models of the structure and growth of discussion threads. These are parametrized network formation models that are able to generate synthetic discussion threads that reproduce certain features of the real discussions present in different online platforms. We aim to provide a clear overview of the state of the art and to motivate future work in this relevant research field.</dcterms:abstract>
        <dc:title>Generative models of online discussion threads: state of the art and research challenges</dc:title>
        <z:shortTitle>Generative models of online discussion threads</z:shortTitle>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1867-4828,%201869-0238">
        <prism:volume>8</prism:volume>
        <prism:number>1</prism:number>
        <dc:title>Journal of Internet Services and Applications</dc:title>
        <dc:identifier>ISSN 1867-4828, 1869-0238</dc:identifier>
        <dc:identifier>DOI 10.1186/s13174-017-0066-z</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_261">
        <z:itemType>attachment</z:itemType>
        <dc:title>Aragón et al. - 2017 - Generative models of online discussion threads st.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://link.springer.com/10.1007/s11280-012-0162-8">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1386-145X,%201573-1413"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gómez</foaf:surname>
                        <foaf:givenname>Vicenç</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kappen</foaf:surname>
                        <foaf:givenname>Hilbert J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Litvak</foaf:surname>
                        <foaf:givenname>Nelly</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kaltenbrunner</foaf:surname>
                        <foaf:givenname>Andreas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_263"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://link.springer.com/10.1007/s11280-012-0162-8</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>645-675</bib:pages>
        <dc:date>11/2013</dc:date>
        <dcterms:dateSubmitted>2019-01-16 21:16:40</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online discussion threads are conversational cascades in the form of posted messages that can be generally found in social systems that comprise many-to-many interaction such as blogs, news aggregators or bulletin board systems. We propose a framework based on generative models of growing trees to analyse the structure and evolution of discussion threads. We consider the growth of a discussion to be determined by an interplay between popularity, novelty and a trend (or bias) to reply to the thread originator. The relevance of these features is estimated using a full likelihood approach and allows to characterise the habits and communication patterns of a given platform and/or community. We apply the proposed framework on four popular websites: Slashdot, Barrapunto (a Spanish version of Slashdot), Meneame (a Spanish Digg-clone) and the article discussion pages of the English Wikipedia. Our results provide significant insight into understanding how discussion cascades grow and have potential applications in broader contexts such as community management or design of communication platforms.</dcterms:abstract>
        <dc:title>A likelihood-based framework for the analysis of discussion threads</dc:title>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1386-145X,%201573-1413">
        <prism:volume>16</prism:volume>
        <prism:number>5-6</prism:number>
        <dc:title>World Wide Web</dc:title>
        <dc:identifier>ISSN 1386-145X, 1573-1413</dc:identifier>
        <dc:identifier>DOI 10.1007/s11280-012-0162-8</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_263">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gómez et al. - 2013 - A likelihood-based framework for the analysis of d.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="#item_267">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>DOI 10.18653/v1/S17-2083</dc:identifier>
                <dc:title>Proceedings of the 11th International Workshop on Semantic Evaluation           (SemEval-2017)</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Vancouver, Canada</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Association for Computational Linguistics</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kochkina</foaf:surname>
                        <foaf:givenname>Elena</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liakata</foaf:surname>
                        <foaf:givenname>Maria</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Augenstein</foaf:surname>
                        <foaf:givenname>Isabelle</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_266"/>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://aclweb.org/anthology/S17-2083</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>475-480</bib:pages>
        <dc:date>2017</dc:date>
        <dcterms:dateSubmitted>2019-01-17 12:58:14</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the 11th International Workshop on Semantic Evaluation           (SemEval-2017)</dc:title>
            </bib:Conference>
        </bib:presentedAt>
        <z:language>en</z:language>
        <dcterms:abstract>This paper describes team Turing’s submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classiﬁcation, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classiﬁcation is considered to be an important step towards rumour veriﬁcation, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying rumours. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an accuracy of 0.784 on the RumourEval test set outperforming all other systems in Subtask A.</dcterms:abstract>
        <dc:title>Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM</dc:title>
        <z:shortTitle>Turing at SemEval-2017 Task 8</z:shortTitle>
    </rdf:Description>
    <z:Attachment rdf:about="#item_266">
        <z:itemType>attachment</z:itemType>
        <dc:title>Kochkina et al. - 2017 - Turing at SemEval-2017 Task 8 Sequential Approach.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1708.06834">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1708.06834 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Campos</foaf:surname>
                        <foaf:givenname>Victor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jou</foaf:surname>
                        <foaf:givenname>Brendan</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Giro-i-Nieto</foaf:surname>
                        <foaf:givenname>Xavier</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Torres</foaf:surname>
                        <foaf:givenname>Jordi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chang</foaf:surname>
                        <foaf:givenname>Shih-Fu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_272"/>
        <link:link rdf:resource="#item_269"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Computer Vision and Pattern Recognition</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1708.06834</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2017-08-22</dc:date>
        <dc:description>arXiv: 1708.06834</dc:description>
        <dcterms:dateSubmitted>2019-02-02 22:04:18</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Recurrent Neural Networks (RNNs) continue to show outstanding performance in sequence modeling tasks. However, training RNNs on long sequences often face challenges like slow inference, vanishing gradients and difﬁculty in capturing long term dependencies. In backpropagation through time settings, these issues are tightly coupled with the large, sequential computational graph resulting from unfolding the RNN in time. We introduce the Skip RNN model which extends existing RNN models by learning to skip state updates and shortens the effective size of the computational graph. This model can also be encouraged to perform fewer state updates through a budget constraint. We evaluate the proposed model on various tasks and show how it can reduce the number of required RNN updates while preserving, and sometimes even improving, the performance of the baseline RNN models. Source code is publicly available at https://imatge-upc. github.io/skiprnn-2017-telecombcn/.</dcterms:abstract>
        <dc:title>Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks</dc:title>
        <z:shortTitle>Skip RNN</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_272">
       <rdf:value>Comment: Accepted as conference paper at ICLR 2018</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_269">
        <z:itemType>attachment</z:itemType>
        <dc:title>Campos et al. - 2017 - Skip RNN Learning to Skip State Updates in Recurr.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_273">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Risch</foaf:surname>
                        <foaf:givenname>Julian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Garda</foaf:surname>
                        <foaf:givenname>Samuele</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krestel</foaf:surname>
                        <foaf:givenname>Ralf</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_270"/>
        <bib:pages>12</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Content-based recommendation of books and other media is usually based on semantic similarity measures. While metadata can be compared easily, measuring the semantic similarity of narrative literature is challenging. Keyword-based approaches are biased to retrieve books of the same series or do not retrieve any results at all in sparser libraries. We propose to represent plots with dense vectors to foster semantic search for similar plots even if they do not have any words in common. Further, we propose to embed plots, places, and times in the same embedding space. Thereby, we allow arithmetics on these aspects. For example, a book with a similar plot but set in a diﬀerent, user-speciﬁed place can be retrieved. We evaluate our ﬁndings on a set of 16,000 book synopses that spans literature from 500 years and 200 genres and compare our approach to a keyword-based baseline.</dcterms:abstract>
        <dc:title>Book Recommendations Beyond the Usual Suspects</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_270">
        <z:itemType>attachment</z:itemType>
        <dc:title>Risch et al. - Book Recommendations Beyond the Usual Suspects.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_276">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wu</foaf:surname>
                        <foaf:givenname>Huijia</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhang</foaf:surname>
                        <foaf:givenname>Jiajun</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zong</foaf:surname>
                        <foaf:givenname>Chengqing</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_275"/>
        <bib:pages>10</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>In this paper, we empirically explore the effects of various kinds of skip connections in stacked bidirectional LSTMs for sequential tagging. We investigate three kinds of skip connections connecting to LSTM cells: (a) skip connections to the gates, (b) skip connections to the internal states and (c) skip connections to the cell outputs. We present comprehensive experiments showing that skip connections to cell outputs outperform the remaining two. Furthermore, we observe that using gated identity functions as skip mappings works pretty well. Based on this novel skip connections, we successfully train deep stacked bidirectional LSTM models and obtain state-ofthe-art results on CCG supertagging and comparable results on POS tagging.</dcterms:abstract>
        <dc:title>An Empirical Exploration of Skip Connections for Sequential Tagging</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_275">
        <z:itemType>attachment</z:itemType>
        <dc:title>Wu et al. - An Empirical Exploration of Skip Connections for S.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1808.09115">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1808.09115 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gröndahl</foaf:surname>
                        <foaf:givenname>Tommi</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pajola</foaf:surname>
                        <foaf:givenname>Luca</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Juuti</foaf:surname>
                        <foaf:givenname>Mika</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Conti</foaf:surname>
                        <foaf:givenname>Mauro</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Asokan</foaf:surname>
                        <foaf:givenname>N.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_281"/>
        <link:link rdf:resource="#item_279"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1808.09115</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-08-28</dc:date>
        <dc:description>arXiv: 1808.09115</dc:description>
        <dcterms:dateSubmitted>2019-02-04 16:44:16</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>With the spread of social networks and their unfortunate use for hate speech, automatic detection of the la er has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are bri le against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also eﬀective against Google Perspective – a cu ingedge solution from industry. Our experiments demonstrate that adversarial training does not completely mitigate the a acks, and using character-level features makes the models systematically more a ack-resistant than using word-level features.</dcterms:abstract>
        <dc:title>All You Need is &quot;Love&quot;: Evading Hate-speech Detection</dc:title>
        <z:shortTitle>All You Need is &quot;Love&quot;</z:shortTitle>
    </bib:Article>
    <bib:Memo rdf:about="#item_281">
        <rdf:value>Comment: 11 pages, Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security (AISec) 2018</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_279">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gröndahl et al. - 2018 - All You Need is Love Evading Hate-speech Detect.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_283">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Godde</foaf:surname>
                        <foaf:givenname>Christian</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lazaridou</foaf:surname>
                        <foaf:givenname>Konstantina</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krestel</foaf:surname>
                        <foaf:givenname>Ralf</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_282"/>
        <bib:pages>12</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Online news has gradually become an inherent part of many people’s every day life, with the media enabling a social and interactive consumption of news as well. Readers openly express their perspectives and emotions for a current event by commenting news articles. They also form online communities and interact with each other by replying to other users’ comments. Due to their active and signiﬁcant role in the diﬀusion of information, automatically gaining insights of these comments’ content is an interesting task. We are especially interested in ﬁnding systematic diﬀerences among the user comments from different newspapers. To this end, we propose the following classiﬁcation task: Given a news comment thread of a particular article, identify the newspaper it comes from. Our corpus consists of six well-known German newspapers and their comments. We propose two experimental settings using SVM classiﬁers build on comment- and article-based features. We achieve precision of up to 90% for individual newspapers.</dcterms:abstract>
        <dc:title>Classiﬁcation of German Newspaper Comments</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_282">
        <z:itemType>attachment</z:itemType>
        <dc:title>Godde et al. - Classiﬁcation of German Newspaper Comments.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:BookSection rdf:about="urn:isbn:978-1-315-27044-9">
        <z:itemType>bookSection</z:itemType>
        <dcterms:isPartOf>
            <bib:Book>
                <dc:identifier>ISBN 978-1-315-27044-9</dc:identifier>
                <dc:title>The Routledge Handbook of Developments in Digital Journalism Studies</dc:title>
            </bib:Book>
        </dcterms:isPartOf>
        <dc:publisher>
           <foaf:Organization><foaf:name>Routledge</foaf:name></foaf:Organization>
        </dc:publisher>
        <z:bookAuthors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Eldridge II</foaf:surname>
                        <foaf:givenname>Scott</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:bookAuthors>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ksiazek</foaf:surname>
                        <foaf:givenname>Thomas B.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_284"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.taylorfrancis.com/books/9781351982092/chapters/10.4324/9781315270449-37</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <prism:edition>1</prism:edition>
        <bib:pages>475-486</bib:pages>
        <dc:date>2018-9-3</dc:date>
        <dc:description>DOI: 10.4324/9781315270449-37</dc:description>
        <dcterms:dateSubmitted>2019-02-04 17:08:00</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dc:title>User Comments in Digital Journalism</dc:title>
    </bib:BookSection>
    <z:Attachment rdf:about="#item_284">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ksiazek - 2018 - User Comments in Digital Journalism.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1810.12264">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1810.12264 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lin</foaf:surname>
                        <foaf:givenname>Zhaojiang</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Winata</foaf:surname>
                        <foaf:givenname>Genta Indra</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fung</foaf:surname>
                        <foaf:givenname>Pascale</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_288"/>
        <link:link rdf:resource="#item_286"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1810.12264</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-10-29</dc:date>
        <dc:description>arXiv: 1810.12264</dc:description>
        <dcterms:dateSubmitted>2019-02-05 14:26:21</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Existing models on open-domain comment generation are difﬁcult to train, and they produce repetitive and uninteresting responses. The problem is due to multiple and contradictory responses from a single article, and by the rigidity of retrieval methods. To solve this problem, we propose a combined approach to retrieval and generation methods. We propose an attentive scorer to retrieve informative and relevant comments by leveraging user-generated data. Then, we use such comments, together with the article, as input for a sequence-to-sequence model with copy mechanism. We show the robustness of our model and how it can alleviate the aforementioned issue by using a large scale comment generation dataset. The result shows that the proposed generative model signiﬁcantly outperforms strong baseline such as Seq2Seq with attention and Information Retrieval models by around 27 and 30 BLEU-1 points respectively.</dcterms:abstract>
        <dc:title>Learning Comment Generation by Leveraging User-Generated Data</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_288">
       <rdf:value>Comment: Submitted to ICASSP 2019</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_286">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lin et al. - 2018 - Learning Comment Generation by Leveraging User-Gen.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1809.04960">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1809.04960 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ma</foaf:surname>
                        <foaf:givenname>Shuming</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cui</foaf:surname>
                        <foaf:givenname>Lei</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wei</foaf:surname>
                        <foaf:givenname>Furu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sun</foaf:surname>
                        <foaf:givenname>Xu</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_289"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1809.04960</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-09-13</dc:date>
        <dc:description>arXiv: 1809.04960</dc:description>
        <dcterms:dateSubmitted>2019-02-05 14:26:26</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Article comments can provide supplementary opinions and facts for readers, thereby increase the attraction and engagement of articles. Therefore, automatically commenting is helpful in improving the activeness of the community, such as online forums and news websites. Previous work shows that training an automatic commenting system requires large parallel corpora. Although part of articles are naturally paired with the comments on some websites, most articles and comments are unpaired on the Internet. To fully exploit the unpaired data, we completely remove the need for parallel data and propose a novel unsupervised approach to train an automatic article commenting model, relying on nothing but unpaired articles and comments. Our model is based on a retrieval-based commenting framework, which uses news to retrieve comments based on the similarity of their topics. The topic representation is obtained from a neural variational topic model, which is trained in an unsupervised manner. We evaluate our model on a news comment dataset. Experiments show that our proposed topic-based approach signiﬁcantly outperforms previous lexicon-based models. The model also proﬁts from paired corpora and achieves state-of-the-art performance under semi-supervised scenarios.</dcterms:abstract>
        <dc:title>Unsupervised Machine Commenting with Neural Variational Topic Model</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_289">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ma et al. - 2018 - Unsupervised Machine Commenting with Neural Variat.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1901.07291">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1901.07291 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lample</foaf:surname>
                        <foaf:givenname>Guillaume</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Conneau</foaf:surname>
                        <foaf:givenname>Alexis</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_291"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1901.07291</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2019-01-22</dc:date>
        <dc:description>arXiv: 1901.07291</dc:description>
        <dcterms:dateSubmitted>2019-02-05 15:12:37</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Recent studies have demonstrated the efﬁciency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models (XLMs): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classiﬁcation, unsupervised and supervised machine translation. On XNLI, our approach pushes the state of the art by an absolute gain of 4.9% accuracy. On unsupervised machine translation, we obtain 34.3 BLEU on WMT’16 German-English, improving the previous state of the art by more than 9 BLEU. On supervised machine translation, we obtain a new state of the art of 38.5 BLEU on WMT’16 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models will be made publicly available.</dcterms:abstract>
        <dc:title>Cross-lingual Language Model Pretraining</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_291">
        <z:itemType>attachment</z:itemType>
        <dc:title>Lample and Conneau - 2019 - Cross-lingual Language Model Pretraining.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_294">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Micikeviˇcius</foaf:surname>
                        <foaf:givenname>Paulius</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Caminiti</foaf:surname>
                        <foaf:givenname>Saverio</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Deo</foaf:surname>
                        <foaf:givenname>Narsingh</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_293"/>
        <bib:pages>11</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>In this paper we present O(n)-time algorithms for encoding/decoding n-node labeled trees as sequences of n − 2 node labels. All known encodings of this type are covered, including Pru¨fer-like codes and the three codes proposed by Picciotto - the happy, blob, and dandelion codes. The algorithms for Picciotto’s codes are of special signiﬁcance as previous publications describe suboptimal approaches requiring O(n log n) or even O(n2) time.</dcterms:abstract>
        <dc:title>Linear-time Algorithms for Encoding Trees as Sequences of Node Labels</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_293">
        <z:itemType>attachment</z:itemType>
        <dc:title>Micikeviˇcius et al. - Linear-time Algorithms for Encoding Trees as Seque.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_297">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jiang</foaf:surname>
                        <foaf:givenname>Ling</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_296"/>
        <bib:pages>5</bib:pages>
        <dc:date>2019</dc:date>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Journalists and news audiences value conversations sparked by news articles. Thus, online comment sections are of significance to news organizations that encourage exchange of valuable ideas and want to achieve community journalism. However, comment sections come with inherent challenges. Trolls and bullies can crowd out thoughtful discussion and criticism if they are left untended, but manual moderation is expensive and infeasible at a massive scale. The Washington Post decided to address the problem by creating an automatic comment moderation system, which we called ModBot, using Natural Language Processing (NLP) and Machine Learning techniques. ModBot’s main contribution lies in scaling up the moderation process. It automatically generates a moderation score for each comment to minimize the efforts for the newsroom. Right now, ModBot moderates more than 400% as many comments as human moderators reviewed in a month, and the number can increase as we keep improving ModBot. In this paper, we present ModBot and describe the challenges we came across during the development process. We also discuss future directions for improving ModBot.</dcterms:abstract>
        <dc:title>ModBot: Automatic Comments Moderation</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_296">
        <z:itemType>attachment</z:itemType>
        <dc:title>Jiang - 2019 - ModBot Automatic Comments Moderation.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1808.06161">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1808.06161 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Jin</foaf:surname>
                        <foaf:givenname>Di</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Szolovits</foaf:surname>
                        <foaf:givenname>Peter</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_301"/>
        <link:link rdf:resource="#item_299"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1808.06161</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-08-19</dc:date>
        <dc:description>arXiv: 1808.06161</dc:description>
        <dcterms:dateSubmitted>2019-02-13 21:40:10</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Prevalent models based on artiﬁcial neural network (ANN) for sentence classiﬁcation often classify sentences in isolation without considering the context in which sentences appear. This hampers the traditional sentence classiﬁcation approaches to the problem of sequential sentence classiﬁcation, where structured prediction is needed for better overall classiﬁcation performance. In this work, we present a hierarchical sequential labeling network to make use of the contextual information within surrounding sentences to help classify the current sentence. Our model outperforms the state-of-the-art results by 2%-3% on two benchmarking datasets for sequential sentence classiﬁcation in medical scientiﬁc abstracts.</dcterms:abstract>
        <dc:title>Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts</dc:title>
    </bib:Article>
    <bib:Memo rdf:about="#item_301">
       <rdf:value>Comment: Accepted by EMNLP 2018</rdf:value>
    </bib:Memo>
    <z:Attachment rdf:about="#item_299">
        <z:itemType>attachment</z:itemType>
        <dc:title>Jin and Szolovits - 2018 - Hierarchical Neural Networks for Sequential Senten.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1712.02223">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:03064573"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zubiaga</foaf:surname>
                        <foaf:givenname>Arkaitz</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Kochkina</foaf:surname>
                        <foaf:givenname>Elena</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liakata</foaf:surname>
                        <foaf:givenname>Maria</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Procter</foaf:surname>
                        <foaf:givenname>Rob</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lukasik</foaf:surname>
                        <foaf:givenname>Michal</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bontcheva</foaf:surname>
                        <foaf:givenname>Kalina</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Cohn</foaf:surname>
                        <foaf:givenname>Trevor</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Augenstein</foaf:surname>
                        <foaf:givenname>Isabelle</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_302"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Social and Information Networks</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1712.02223</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>273-290</bib:pages>
        <dc:date>03/2018</dc:date>
        <dc:description>arXiv: 1712.02223</dc:description>
        <dcterms:dateSubmitted>2019-02-14 12:48:11</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Rumour stance classification, defined as classifying the stance of specific social media posts into one of supporting, denying, querying or commenting on an earlier post, is becoming of increasing interest to researchers. While most previous work has focused on using individual tweets as classifier inputs, here we report on the performance of sequential classifiers that exploit the discourse features inherent in social media interactions or 'conversational threads'. Testing the effectiveness of four sequential classifiers -- Hawkes Processes, Linear-Chain Conditional Random Fields (Linear CRF), Tree-Structured Conditional Random Fields (Tree CRF) and Long Short Term Memory networks (LSTM) -- on eight datasets associated with breaking news stories, and looking at different types of local and contextual features, our work sheds new light on the development of accurate stance classifiers. We show that sequential classifiers that exploit the use of discourse properties in social media conversations while using only local features, outperform non-sequential classifiers. Furthermore, we show that LSTM using a reduced set of features can outperform the other sequential classifiers; this performance is consistent across datasets and across types of stances. To conclude, our work also analyses the different features under study, identifying those that best help characterise and distinguish between stances, such as supporting tweets being more likely to be accompanied by evidence than denying tweets. We also set forth a number of directions for future research.</dcterms:abstract>
        <dc:title>Discourse-Aware Rumour Stance Classification in Social Media Using Sequential Classifiers</dc:title>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:03064573">
        <prism:volume>54</prism:volume>
        <prism:number>2</prism:number>
        <dc:title>Information Processing &amp; Management</dc:title>
        <dc:identifier>ISSN 03064573</dc:identifier>
        <dc:identifier>DOI 10.1016/j.ipm.2017.11.009</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_302">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zubiaga et al. - 2018 - Discourse-Aware Rumour Stance Classification in So.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="#item_305">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Radford</foaf:surname>
                        <foaf:givenname>Alec</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wu</foaf:surname>
                        <foaf:givenname>Jeffrey</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Child</foaf:surname>
                        <foaf:givenname>Rewon</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Luan</foaf:surname>
                        <foaf:givenname>David</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Amodei</foaf:surname>
                        <foaf:givenname>Dario</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sutskever</foaf:surname>
                        <foaf:givenname>Ilya</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_304"/>
        <bib:pages>24</bib:pages>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts WebText. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.</dcterms:abstract>
        <dc:title>Language Models are Unsupervised Multitask Learners</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_304">
        <z:itemType>attachment</z:itemType>
        <dc:title>Radford et al. - Language Models are Unsupervised Multitask Learner.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="http://arxiv.org/abs/1803.08240">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal><dc:title>arXiv:1803.08240 [cs]</dc:title></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Merity</foaf:surname>
                        <foaf:givenname>Stephen</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Keskar</foaf:surname>
                        <foaf:givenname>Nitish Shirish</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Socher</foaf:surname>
                        <foaf:givenname>Richard</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_195"/>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Computation and Language</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Computer Science - Artificial Intelligence</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
                <rdf:value>Computer Science - Neural and Evolutionary Computing</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>http://arxiv.org/abs/1803.08240</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:date>2018-03-22</dc:date>
        <dc:description>arXiv: 1803.08240</dc:description>
        <dcterms:dateSubmitted>2019-02-14 18:20:34</dcterms:dateSubmitted>
        <z:libraryCatalog>arXiv.org</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Many of the leading approaches in language modeling introduce novel, complex and specialized architectures. We take existing state-of-the-art word level language models based on LSTMs and QRNNs and extend them to both larger vocabularies as well as character-level granularity. When properly tuned, LSTMs and QRNNs achieve stateof-the-art results on character-level (Penn Treebank, enwik8) and word-level (WikiText-103) datasets, respectively. Results are obtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single modern GPU.</dcterms:abstract>
        <dc:title>An Analysis of Neural Language Modeling at Multiple Scales</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_195">
        <z:itemType>attachment</z:itemType>
        <dc:title>Merity et al. - 2018 - An Analysis of Neural Language Modeling at Multipl.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="http://localhost:8888/tree/masters-thesis/ynacc/12">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_308"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://localhost:8888/tree/masters-thesis/ynacc/12</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2019-02-15 15:03:11</dcterms:dateSubmitted>
        <dc:title>masters-thesis/ynacc/12/</dc:title>
    </bib:Document>
    <z:Attachment rdf:about="#item_308">
        <z:itemType>attachment</z:itemType>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://localhost:8888/tree/masters-thesis/ynacc/12</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2019-02-15 15:03:12</dcterms:dateSubmitted>
        <dc:title>masters-thesis/ynacc/12/</dc:title>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://linkinghub.elsevier.com/retrieve/pii/S0306457309000259">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <prism:volume>45</prism:volume>
                <prism:number>4</prism:number>
                <dc:title>Information Processing &amp; Management</dc:title>
                <dc:identifier>ISSN 03064573</dc:identifier>
                <dc:identifier>DOI 10.1016/j.ipm.2009.03.002</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sokolova</foaf:surname>
                        <foaf:givenname>Marina</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lapalme</foaf:surname>
                        <foaf:givenname>Guy</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_192"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://linkinghub.elsevier.com/retrieve/pii/S0306457309000259</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>427-437</bib:pages>
        <dc:date>7/2009</dc:date>
        <dcterms:dateSubmitted>2019-02-21 11:38:47</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classiﬁcation tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classiﬁcation task, the study relates a set of changes in a confusion matrix to speciﬁc characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classiﬁer’s evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classiﬁcation problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classiﬁers. Text classiﬁcation supplements the discussion with several case studies.</dcterms:abstract>
        <dc:title>A systematic analysis of performance measures for classification tasks</dc:title>
    </bib:Article>
    <z:Attachment rdf:about="#item_192">
        <z:itemType>attachment</z:itemType>
        <dc:title>Sokolova and Lapalme - 2009 - A systematic analysis of performance measures for .pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://linkinghub.elsevier.com/retrieve/pii/S0167865508002687">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:01678655"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ferri</foaf:surname>
                        <foaf:givenname>C.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hernández-Orallo</foaf:surname>
                        <foaf:givenname>J.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Modroiu</foaf:surname>
                        <foaf:givenname>R.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_311"/>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://linkinghub.elsevier.com/retrieve/pii/S0167865508002687</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>27-38</bib:pages>
        <dc:date>1/2009</dc:date>
        <dcterms:dateSubmitted>2019-02-21 11:39:06</dcterms:dateSubmitted>
        <z:libraryCatalog>Crossref</z:libraryCatalog>
        <z:language>en</z:language>
        <dcterms:abstract>Performance metrics in classiﬁcation are fundamental in assessing the quality of learning methods and learned models. However, many different measures have been deﬁned in the literature with the aim of making better choices in general or for a speciﬁc application area. Choices made by one metric are claimed to be different from choices made by other metrics. In this work, we analyse experimentally the behaviour of 18 different performance metrics in several scenarios, identifying clusters and relationships between measures. We also perform a sensitivity analysis for all of them in terms of several traits: class threshold choice, separability/ranking quality, calibration performance and sensitivity to changes in prior class distribution. From the deﬁnitions and experiments, we make a comprehensive analysis of the relationships between metrics, and a taxonomy and arrangement of them according to the previous traits. This can be useful for choosing the most adequate measure (or set of measures) for a speciﬁc application. Additionally, the study also highlights some niches in which new measures might be deﬁned and also shows that some supposedly innovative measures make the same choices (or almost) as existing ones. Finally, this work can also be used as a reference for comparing experimental results in pattern recognition and machine learning literature, when using different measures.</dcterms:abstract>
        <dc:title>An experimental comparison of performance measures for classification</dc:title>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:01678655">
        <prism:volume>30</prism:volume>
        <prism:number>1</prism:number>
        <dc:title>Pattern Recognition Letters</dc:title>
        <dc:identifier>ISSN 01678655</dc:identifier>
        <dc:identifier>DOI 10.1016/j.patrec.2008.08.010</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_311">
        <z:itemType>attachment</z:itemType>
        <dc:title>Ferri et al. - 2009 - An experimental comparison of performance measures.pdf</dc:title>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:BookSection rdf:about="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">
        <z:itemType>bookSection</z:itemType>
        <dcterms:isPartOf>
            <bib:Book>
                <dc:title>Advances in Neural Information Processing Systems 25</dc:title>
            </bib:Book>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Curran Associates, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Krizhevsky</foaf:surname>
                        <foaf:givenname>Alex</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sutskever</foaf:surname>
                        <foaf:givenname>Ilya</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hinton</foaf:surname>
                        <foaf:givenname>Geoffrey E</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:editors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pereira</foaf:surname>
                        <foaf:givenname>F.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Burges</foaf:surname>
                        <foaf:givenname>C. J. C.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bottou</foaf:surname>
                        <foaf:givenname>L.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weinberger</foaf:surname>
                        <foaf:givenname>K. Q.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:editors>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>1097–1105</bib:pages>
        <dc:date>2012</dc:date>
        <dc:title>ImageNet Classification with Deep Convolutional Neural Networks</dc:title>
    </bib:BookSection>
    <bib:BookSection rdf:about="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">
        <z:itemType>bookSection</z:itemType>
        <dcterms:isPartOf>
            <bib:Book>
                <dc:title>Advances in Neural Information Processing Systems 26</dc:title>
            </bib:Book>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
               <foaf:name>Curran Associates, Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mikolov</foaf:surname>
                        <foaf:givenname>Tomas</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sutskever</foaf:surname>
                        <foaf:givenname>Ilya</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chen</foaf:surname>
                        <foaf:givenname>Kai</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Corrado</foaf:surname>
                        <foaf:givenname>Greg S</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dean</foaf:surname>
                        <foaf:givenname>Jeff</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:editors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Burges</foaf:surname>
                        <foaf:givenname>C. J. C.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bottou</foaf:surname>
                        <foaf:givenname>L.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Welling</foaf:surname>
                        <foaf:givenname>M.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ghahramani</foaf:surname>
                        <foaf:givenname>Z.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Weinberger</foaf:surname>
                        <foaf:givenname>K. Q.</foaf:givenname>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:editors>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <bib:pages>3111–3119</bib:pages>
        <dc:date>2013</dc:date>
        <dc:title>Distributed Representations of Words and Phrases and their Compositionality</dc:title>
    </bib:BookSection>
    <z:Collection rdf:about="#collection_31">
        <dc:title>Books</dc:title>
        <dcterms:hasPart rdf:resource="#item_163"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-0-07-042807-2"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.09820"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_37">
        <dc:title>Classification</dc:title>
        <dcterms:hasPart rdf:resource="#item_193"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1809.05679"/>
        <dcterms:hasPart rdf:resource="https://linkinghub.elsevier.com/retrieve/pii/S0306457309000259"/>
        <dcterms:hasPart rdf:resource="https://linkinghub.elsevier.com/retrieve/pii/S0167865508002687"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_41">
        <dc:title>Context</dc:title>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/D17-1231"/>
        <dcterms:hasPart rdf:resource="#item_229"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1704.06380"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/N16-1149"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_12">
        <dc:title>Hate Speech ML</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1703.04009"/>
        <dcterms:hasPart rdf:resource="#item_55"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-4143-1"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-1101"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.09115"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_29">
        <dc:title>Hatespeech Data</dc:title>
        <dcterms:hasPart rdf:resource="#item_158"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1705.09993"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_33">
        <dc:title>HPI</dc:title>
        <dcterms:hasPart rdf:resource="#item_174"/>
        <dcterms:hasPart rdf:resource="#item_175"/>
        <dcterms:hasPart rdf:resource="#item_176"/>
        <dcterms:hasPart rdf:resource="#item_177"/>
        <dcterms:hasPart rdf:resource="#item_273"/>
        <dcterms:hasPart rdf:resource="#item_283"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_23">
        <dc:title>News Comments</dc:title>
        <dcterms:hasPart rdf:resource="#collection_5"/>
        <dcterms:hasPart rdf:resource="#collection_13"/>
        <dcterms:hasPart rdf:resource="#collection_2"/>
        <dcterms:hasPart rdf:resource="#collection_10"/>
        <dcterms:hasPart rdf:resource="#collection_25"/>
        <dcterms:hasPart rdf:resource="#collection_48"/>
        <dcterms:hasPart rdf:resource="#collection_8"/>
        <dcterms:hasPart rdf:resource="#collection_11"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_5">
        <dc:title>Closly Relevant</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.07191"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1710.07395"/>
        <dcterms:hasPart rdf:resource="#item_297"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Closly Relevant</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.07191"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1710.07395"/>
        <dcterms:hasPart rdf:resource="#item_297"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_13">
        <dc:title>Early Work UGC</dc:title>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-58113-702-6"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-60558-085-2"/>
        <dcterms:hasPart rdf:resource="http://portal.acm.org/citation.cfm?doid=1787234.1787254"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Early Work UGC</dc:title>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-58113-702-6"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-60558-085-2"/>
        <dcterms:hasPart rdf:resource="http://portal.acm.org/citation.cfm?doid=1787234.1787254"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_2">
        <dc:title>News Comments ML</dc:title>
        <dcterms:hasPart rdf:resource="#item_12"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-4218"/>
        <dcterms:hasPart rdf:resource="#item_14"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-3002"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-3362-7"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1805.03668"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-4144-8"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.01114"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>News Comments ML</dc:title>
        <dcterms:hasPart rdf:resource="#item_12"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-4218"/>
        <dcterms:hasPart rdf:resource="#item_14"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-3002"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-3362-7"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1805.03668"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-4144-8"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.01114"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_10">
        <dc:title>News Data / Corpus</dc:title>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-0802"/>
        <dcterms:hasPart rdf:resource="#item_16"/>
        <dcterms:hasPart rdf:resource="#item_30"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-5022-8"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>News Data / Corpus</dc:title>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-0802"/>
        <dcterms:hasPart rdf:resource="#item_16"/>
        <dcterms:hasPart rdf:resource="#item_30"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-5022-8"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_25">
        <dc:title>Product Reviews</dc:title>
        <dcterms:hasPart rdf:resource="https://linkinghub.elsevier.com/retrieve/pii/S0148296316304957"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-4675-7"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Product Reviews</dc:title>
        <dcterms:hasPart rdf:resource="https://linkinghub.elsevier.com/retrieve/pii/S0148296316304957"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-4675-7"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_48">
        <dc:title>recent</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.12264"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1809.04960"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>recent</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.12264"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1809.04960"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_8">
        <dc:title>Social Sciences: Comments</dc:title>
        <dcterms:hasPart rdf:resource="#item_39"/>
        <dcterms:hasPart rdf:resource="#item_44"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-0556-3"/>
        <dcterms:hasPart rdf:resource="#item_48"/>
        <dcterms:hasPart rdf:resource="https://www.tandfonline.com/doi/full/10.1080/1369118X.2017.1324505"/>
        <dcterms:hasPart rdf:resource="https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1209977"/>
        <dcterms:hasPart rdf:resource="http://econtent.hogrefe.com/doi/10.1027/1864-1105/a000217"/>
        <dcterms:hasPart rdf:resource="https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1161497"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-315-27044-9"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Social Sciences: Comments</dc:title>
        <dcterms:hasPart rdf:resource="#item_39"/>
        <dcterms:hasPart rdf:resource="#item_44"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-0556-3"/>
        <dcterms:hasPart rdf:resource="#item_48"/>
        <dcterms:hasPart rdf:resource="https://www.tandfonline.com/doi/full/10.1080/1369118X.2017.1324505"/>
        <dcterms:hasPart rdf:resource="https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1209977"/>
        <dcterms:hasPart rdf:resource="http://econtent.hogrefe.com/doi/10.1027/1864-1105/a000217"/>
        <dcterms:hasPart rdf:resource="https://www.tandfonline.com/doi/full/10.1080/1461670X.2016.1161497"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-315-27044-9"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_11">
        <dc:title>Summary Comments</dc:title>
        <dcterms:hasPart rdf:resource="#item_50"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Summary Comments</dc:title>
        <dcterms:hasPart rdf:resource="#item_50"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_20">
        <dc:title>NLP</dc:title>
        <dcterms:hasPart rdf:resource="#collection_7"/>
        <dcterms:hasPart rdf:resource="#collection_22"/>
        <dcterms:hasPart rdf:resource="#collection_49"/>
        <dcterms:hasPart rdf:resource="#collection_17"/>
        <dcterms:hasPart rdf:resource="#collection_21"/>
        <dcterms:hasPart rdf:resource="#collection_16"/>
        <dcterms:hasPart rdf:resource="#collection_18"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1705.02364"/>
        <dcterms:hasPart rdf:resource="#item_125"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1805.10369"/>
        <dcterms:hasPart rdf:resource="#item_131"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_7">
        <dc:title>Features</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1702.05638"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Features</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1702.05638"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_22">
        <dc:title>language model</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1708.02182"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.08949"/>
        <dcterms:hasPart rdf:resource="#item_305"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.08240"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>language model</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1708.02182"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.08949"/>
        <dcterms:hasPart rdf:resource="#item_305"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.08240"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_49">
        <dc:title>LM Finetuning</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1801.06146"/>
        <dcterms:hasPart rdf:resource="#item_83"/>
        <dcterms:hasPart rdf:resource="#item_129"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.08949"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.04805"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1901.07291"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>LM Finetuning</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1801.06146"/>
        <dcterms:hasPart rdf:resource="#item_83"/>
        <dcterms:hasPart rdf:resource="#item_129"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.08949"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.04805"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1901.07291"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_17">
        <dc:title>Oldschool Word Embeddings</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1301.3781"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/D14-1162"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1607.04606"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Oldschool Word Embeddings</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1301.3781"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/D14-1162"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1607.04606"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_21">
        <dc:title>Stance Detection</dc:title>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/S17-2083"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Stance Detection</dc:title>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/S17-2083"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_16">
        <dc:title>Text Matching</dc:title>
        <dcterms:hasPart rdf:resource="#item_87"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1702.03814"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1711.04289"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1709.07109"/>
        <dcterms:hasPart rdf:resource="#item_98"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1805.04869"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.00179"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1806.02847"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Text Matching</dc:title>
        <dcterms:hasPart rdf:resource="#item_87"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1702.03814"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1711.04289"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1709.07109"/>
        <dcterms:hasPart rdf:resource="#item_98"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1805.04869"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.00179"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1806.02847"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_18">
        <dc:title>Transfer Learning in NLP</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.11175"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1801.06146"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1806.06259"/>
        <dcterms:hasPart rdf:resource="#item_83"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1806.05662"/>
        <dcterms:hasPart rdf:resource="#item_129"/>
        <dcterms:hasPart rdf:resource="#item_138"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.08949"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1708.00107"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.04805"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>Transfer Learning in NLP</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1803.11175"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1801.06146"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1806.06259"/>
        <dcterms:hasPart rdf:resource="#item_83"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1806.05662"/>
        <dcterms:hasPart rdf:resource="#item_129"/>
        <dcterms:hasPart rdf:resource="#item_138"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.08949"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1708.00107"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1810.04805"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_27">
        <dc:title>Not relevant anymore</dc:title>
        <dcterms:hasPart rdf:resource="#collection_9"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_9">
        <dc:title>News Comments Debates</dc:title>
        <dcterms:hasPart rdf:resource="#item_41"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>News Comments Debates</dc:title>
        <dcterms:hasPart rdf:resource="#item_41"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_43">
        <dc:title>threads</dc:title>
        <dcterms:hasPart rdf:resource="#collection_45"/>
        <dcterms:hasPart rdf:resource="#collection_46"/>
        <dcterms:hasPart rdf:resource="#collection_51"/>
        <dcterms:hasPart rdf:resource="#item_219"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1606.03667"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1608.04808"/>
        <dcterms:hasPart rdf:resource="#item_235"/>
        <dcterms:hasPart rdf:resource="#item_243"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/W17-5523"/>
        <dcterms:hasPart rdf:resource="#item_258"/>
        <dcterms:hasPart rdf:resource="#item_267"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1712.02223"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_45">
        <dc:title>other</dc:title>
        <dcterms:hasPart rdf:resource="#item_212"/>
        <dcterms:hasPart rdf:resource="#item_214"/>
        <dcterms:hasPart rdf:resource="#item_217"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/N18-1164"/>
        <dcterms:hasPart rdf:resource="#item_245"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/D15-1178"/>
        <dcterms:hasPart rdf:resource="#item_294"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.06161"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>other</dc:title>
        <dcterms:hasPart rdf:resource="#item_212"/>
        <dcterms:hasPart rdf:resource="#item_214"/>
        <dcterms:hasPart rdf:resource="#item_217"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/N18-1164"/>
        <dcterms:hasPart rdf:resource="#item_245"/>
        <dcterms:hasPart rdf:resource="http://aclweb.org/anthology/D15-1178"/>
        <dcterms:hasPart rdf:resource="#item_294"/>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1808.06161"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_46">
        <dc:title>related_tree</dc:title>
        <dcterms:hasPart rdf:resource="urn:isbn:978-3-642-20160-8%20978-3-642-20161-5"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-60558-512-3"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-0757-4"/>
        <dcterms:hasPart rdf:resource="#item_256"/>
        <dcterms:hasPart rdf:resource="#item_258"/>
        <dcterms:hasPart rdf:resource="https://jisajournal.springeropen.com/articles/10.1186/s13174-017-0066-z"/>
        <dcterms:hasPart rdf:resource="http://link.springer.com/10.1007/s11280-012-0162-8"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>related_tree</dc:title>
        <dcterms:hasPart rdf:resource="urn:isbn:978-3-642-20160-8%20978-3-642-20161-5"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-60558-512-3"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-1-4503-0757-4"/>
        <dcterms:hasPart rdf:resource="#item_256"/>
        <dcterms:hasPart rdf:resource="#item_258"/>
        <dcterms:hasPart rdf:resource="https://jisajournal.springeropen.com/articles/10.1186/s13174-017-0066-z"/>
        <dcterms:hasPart rdf:resource="http://link.springer.com/10.1007/s11280-012-0162-8"/>
    </z:Collection>
    <z:Collection rdf:about="#collection_51">
        <dc:title>skip</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1708.06834"/>
        <dcterms:hasPart rdf:resource="#item_276"/>
        <rdf:type rdf:resource="http://www.zotero.org/namespaces/export#Collection"/>
        <dc:title>skip</dc:title>
        <dcterms:hasPart rdf:resource="http://arxiv.org/abs/1708.06834"/>
        <dcterms:hasPart rdf:resource="#item_276"/>
    </z:Collection>
</rdf:RDF>
