{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T13:31:38.355544Z",
     "start_time": "2019-01-27T13:31:36.825671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.42\n",
      "saved conder\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import fastai\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import sacred\n",
    "import sklearn.metrics\n",
    "from fastai.basic_train import get_preds\n",
    "from fastai.callbacks import *\n",
    "from fastai.datasets import *\n",
    "from fastai.imports import nn, torch\n",
    "from fastai.metrics import *\n",
    "from fastai.text import *\n",
    "from fastai.text.data import DataBunch\n",
    "from fastai.train import *\n",
    "from fastai.vision import *\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver\n",
    "from sklearn import metrics\n",
    "\n",
    "import news_utils.fastai\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--exp\")\n",
    "# parser.add_argument(\"--device\", type=int)\n",
    "# parser.add_argument(\"--cl\", type=int)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = SimpleNamespace(cl=8, exp='dat_false_par_false_hea_false_bysdid_sep30000')\n",
    "\n",
    "EX_PA = Path('/mnt/data/group07/johannes/ynacc_proc/proper_baseline/exp/' + args.exp)\n",
    "\n",
    "# torch.cuda.set_device(args.device)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "print(fastai.__version__)\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[args.exp]\n",
    "\n",
    "db_name = args.exp + '_cl'\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "myresults = mydb[\"metrics\"].aggregate([{\n",
    "    \"$match\": {\"name\": \"valid_loss\"}  # only consider val loss\n",
    "},\n",
    "    {\"$unwind\": \"$values\"},\n",
    "    {\"$group\":\n",
    "     {'_id': '$_id',\n",
    "      'minval': {'$min': \"$values\"}, 'run_id' : { '$first': '$run_id' }}\n",
    "     },  # find min values\n",
    "    {\"$sort\": {\"minval\": 1}}  # sort\n",
    "])\n",
    "\n",
    "# get best run id in the metrics table\n",
    "best_run_id = sorted(list(myresults), key=lambda x: x['minval'])[0]['run_id']\n",
    "\n",
    "# get the exp id for the language model\n",
    "best_lm_exp_id = list(mydb['runs'].find({'_id': best_run_id}))[0]['config']['exp_id']\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data_lm = TextLMDataBunch.load(EX_PA)\n",
    "learn_lm = language_model_learner(data_lm).load(\n",
    "    EX_PA/\"models\"/best_lm_exp_id, device=\"cpu\")\n",
    "learn_lm.save_encoder('encoder_' + best_lm_exp_id)\n",
    "\n",
    "shutil.move('/mnt/data/group07/johannes/ynacc_proc/proper_baseline/exp/'+ args.exp  + \"/models/\"  + 'encoder_' + best_lm_exp_id + '.pth', '/mnt/data/group07/johannes/ynacc_proc/proper_baseline/expcl/'+ args    .exp  + \"/models/\" + 'encoder_' + best_lm_exp_id + '.pth')\n",
    "\n",
    "\n",
    "learn_lm_vocab = data_lm.train_ds.vocab\n",
    "del data_lm\n",
    "del learn_lm\n",
    "\n",
    "# overwrite EXP for classification\n",
    "EX_PA = Path('/mnt/data/group07/johannes/ynacc_proc/proper_baseline/expcl/' + args.exp)\n",
    "\n",
    "print('saved conder')\n",
    "\n",
    "def setup_data(clas):\n",
    "    UT = Path('~/data/ynacc_proc/proper_baseline/cls/' + 'dat_false_par_false_hea_false')\n",
    "    \n",
    "    data_clas_train = pd.read_csv(UT/'train.csv')\n",
    "    data_clas_val = pd.read_csv(UT/'val.csv')\n",
    "\n",
    "    data_clas_train = data_clas_train[[clas, 'text_proc']]\n",
    "    data_clas_val = data_clas_val[[clas, 'text_proc']]\n",
    "\n",
    "    data_clas_train = data_clas_train.dropna()\n",
    "    data_clas_val = data_clas_val.dropna()\n",
    "\n",
    "    data_clas_train['text_proc'] = data_clas_train['text_proc'].apply(lambda x: 'xx_comment_start ' + x + ' xx_comment_end')\n",
    "    data_clas_val['text_proc'] = data_clas_train['text_proc'].apply(lambda x: 'xx_comment_start ' + x + ' xx_comment_end')\n",
    "\n",
    "    data_clas_train[clas] = data_clas_train[clas].astype(int)\n",
    "    data_clas_val[clas] = data_clas_val[clas].astype(int)\n",
    "\n",
    "    data_clas = TextClasDataBunch.from_df(EX_PA, data_clas_train, data_clas_val,\n",
    "                                          vocab=learn_lm_vocab, bs=32, text_cols=['text_proc'], label_cols=[clas],)\n",
    "    return data_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-27T13:31:36.491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - root - Added new config entry: \"drop_mult\"\n",
      "WARNING - root - Added new config entry: \"lr\"\n",
      "INFO - dat_false_par_false_hea_false_bysdid_sep30000_cl_cltopic - Running command 'run_exp'\n",
      "INFO - dat_false_par_false_hea_false_bysdid_sep30000_cl_cltopic - Started run with ID \"11\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:29 <p><table style='width:525px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>kappa_score</th>\n",
       "    <th>F1_macro</th>\n",
       "    <th>F1_weighted</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.630635</th>\n",
       "    <th>0.624677</th>\n",
       "    <th>0.686106</th>\n",
       "    <th>0.000000</th>\n",
       "    <th>0.406918</th>\n",
       "    <th>0.813835</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group7/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:36 <p><table style='width:525px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>kappa_score</th>\n",
       "    <th>F1_macro</th>\n",
       "    <th>F1_weighted</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.600416</th>\n",
       "    <th>0.626585</th>\n",
       "    <th>0.686106</th>\n",
       "    <th>0.000000</th>\n",
       "    <th>0.406918</th>\n",
       "    <th>0.813835</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/group7/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:525px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>kappa_score</th>\n",
       "    <th>F1_macro</th>\n",
       "    <th>F1_weighted</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='410' class='' max='494', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      83.00% [410/494 00:40<00:08 0.5931]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_for_class(clas, it=5):\n",
    "    print('work on ' + clas)\n",
    "    torch.cuda.empty_cache()\n",
    "    data_clas = setup_data(clas)\n",
    "    encoder_name = 'encoder_' + best_lm_exp_id\n",
    "    drop_mult = 1\n",
    "\n",
    "    learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "    learn.load_encoder(encoder_name)\n",
    "\n",
    "#     optim_lr = news_utils.fastai.get_optimal_lr(learn, runs=3)\n",
    "    optim_lr = 0.005\n",
    "\n",
    "    ex = Experiment(db_name + '_' + clas, interactive=True)\n",
    "    ex.observers.append(MongoObserver.create(db_name=db_name + '_' + clas))\n",
    "\n",
    "    @ex.config\n",
    "    def my_config():\n",
    "        exp_id = datetime.datetime.now().strftime(\"%Y_%_m_%d_%H_%M_%S_%f\")\n",
    "        factor = 2.6\n",
    "        wd = 1e-7\n",
    "        moms = (0.8, 0.7)\n",
    "        full_epochs = 10\n",
    "\n",
    "    @ex.main\n",
    "    def run_exp(exp_id, drop_mult, lr, moms, wd, factor, full_epochs):\n",
    "\n",
    "        lrs = [lr / (factor ** (4 - x)) for x in range(4)] + [lr]\n",
    "\n",
    "        learn = text_classifier_learner(data_clas, drop_mult=drop_mult)\n",
    "        learn.load_encoder(encoder_name)\n",
    "\n",
    "        learn.metrics += [KappaScore(), news_utils.fastai.F1Macro(),\n",
    "                          news_utils.fastai.F1Weighted()] \n",
    "        learn.callbacks += [\n",
    "            SaveModelCallback(learn, name=exp_id),\n",
    "            news_utils.fastai.SacredLogger(learn, ex),\n",
    "        ]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            epochs = 1\n",
    "            if i in [1, 2]:\n",
    "                learn.freeze_to(-i)\n",
    "            else:\n",
    "                learn.unfreeze()\n",
    "                epochs = full_epochs\n",
    "            learn.fit_one_cycle(epochs, np.array(lrs), wd=wd, moms=moms)\n",
    "\n",
    "    for _ in range(it):\n",
    "        ex.run(config_updates={\"lr\": optim_lr, \"drop_mult\": drop_mult})\n",
    "\n",
    "\n",
    "all_classes = ['claudience', 'clpersuasive', 'clsentiment', 'clagreement', 'cldisagreement', 'clinformative', 'clmean', 'clcontroversial', 'cltopic']\n",
    "run_for_class(all_classes[args.cl])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
